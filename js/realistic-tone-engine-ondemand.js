/**
 * é«˜å“è³ªBGMç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰èª­ã¿è¾¼ã¿ç‰ˆï¼‰
 * Tone.js + ãƒªã‚¢ãƒ«æ¥½å™¨ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨ã—ãŸã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰æ¥½å™¨èª­ã¿è¾¼ã¿ã‚·ã‚¹ãƒ†ãƒ 
 */
class RealisticToneEngine {
  constructor() {
    this.samplers = {};
    this.loadingStatus = {};
    this.initialized = false;
    this.currentComposition = null;
    this.currentPlayer = null; // è¿½åŠ : ç¾åœ¨ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼
    
    // åˆ©ç”¨å¯èƒ½æ¥½å™¨ã®å®šç¾©ï¼ˆTone.js-Instrumentså¯¾å¿œï¼‰
    this.availableInstruments = {
      'piano': { name: 'ãƒ”ã‚¢ãƒ', category: 'keyboard' },
      'bass-electric': { name: 'ã‚¨ãƒ¬ã‚­ãƒ™ãƒ¼ã‚¹', category: 'bass' },
      'guitar-acoustic': { name: 'ã‚¢ã‚³ãƒ¼ã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚®ã‚¿ãƒ¼', category: 'strings' },
      'guitar-electric': { name: 'ã‚¨ãƒ¬ã‚­ã‚®ã‚¿ãƒ¼', category: 'strings' },
      'violin': { name: 'ãƒã‚¤ã‚ªãƒªãƒ³', category: 'strings' },
      'cello': { name: 'ãƒã‚§ãƒ­', category: 'strings' },
      'contrabass': { name: 'ã‚³ãƒ³ãƒˆãƒ©ãƒã‚¹', category: 'strings' },
      'harp': { name: 'ãƒãƒ¼ãƒ—', category: 'strings' },
      'saxophone': { name: 'ã‚µãƒƒã‚¯ã‚¹', category: 'wind' },
      'trumpet': { name: 'ãƒˆãƒ©ãƒ³ãƒšãƒƒãƒˆ', category: 'wind' },
      'trombone': { name: 'ãƒˆãƒ­ãƒ³ãƒœãƒ¼ãƒ³', category: 'wind' },
      'french-horn': { name: 'ãƒ•ãƒ¬ãƒ³ãƒãƒ›ãƒ«ãƒ³', category: 'wind' },
      'tuba': { name: 'ãƒãƒ¥ãƒ¼ãƒ', category: 'wind' },
      'flute': { name: 'ãƒ•ãƒ«ãƒ¼ãƒˆ', category: 'wind' },
      'clarinet': { name: 'ã‚¯ãƒ©ãƒªãƒãƒƒãƒˆ', category: 'wind' },
      'bassoon': { name: 'ãƒã‚¹ãƒ¼ãƒ³', category: 'wind' },
      'xylophone': { name: 'ã‚·ãƒ­ãƒ•ã‚©ãƒ³', category: 'percussion' },
      'organ': { name: 'ã‚ªãƒ«ã‚¬ãƒ³', category: 'keyboard' },
      'harmonium': { name: 'ãƒãƒ¼ãƒ¢ãƒ‹ã‚¦ãƒ ', category: 'keyboard' }
    };

    // éŸ³æ¥½ç†è«–ãƒ‡ãƒ¼ã‚¿
    this.scales = {
      'major': [0, 2, 4, 5, 7, 9, 11],
      'minor': [0, 2, 3, 5, 7, 8, 10],
      'pentatonic': [0, 2, 4, 7, 9],
      'blues': [0, 3, 5, 6, 7, 10]
    };

    this.chordProgressions = {
      'pop': ['I', 'V', 'vi', 'IV'],
      'jazz': ['ii', 'V', 'I', 'vi'],
      'rock': ['I', 'VII', 'IV', 'I'],
      'blues': ['I', 'I', 'I', 'I', 'IV', 'IV', 'I', 'I', 'V', 'IV', 'I', 'V'],
      'classical': ['I', 'IV', 'V', 'I']
    };

    this.genres = {
      'pop': { tempo: 120, scale: 'major', progression: 'pop', instruments: ['piano', 'guitar-acoustic', 'bass-electric'] },
      'rock': { tempo: 140, scale: 'minor', progression: 'rock', instruments: ['guitar-electric', 'bass-electric', 'piano'] },
      'jazz': { tempo: 100, scale: 'major', progression: 'jazz', instruments: ['piano', 'saxophone', 'bass-electric'] },
      'classical': { tempo: 80, scale: 'major', progression: 'classical', instruments: ['piano', 'violin', 'cello'] },
      'electronic': { tempo: 128, scale: 'minor', progression: 'pop', instruments: ['organ', 'bass-electric'] },
      'blues': { tempo: 90, scale: 'blues', progression: 'blues', instruments: ['piano', 'guitar-acoustic', 'saxophone'] }
    };
  }

  /**
   * ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ï¼ˆè»½é‡ç‰ˆï¼‰
   */
  async initialize() {
    try {
      console.log('RealisticToneEngine: Initializing (on-demand loading mode)...');
      
      // Tone.jsã®é–‹å§‹
      if (typeof Tone === 'undefined') {
        throw new Error('Tone.js is not loaded');
      }

      if (Tone.context.state !== 'running') {
        console.log('AudioContext will start on user interaction');
      }

      // åˆæœŸåŒ–æ™‚ã¯æ¥½å™¨ã‚’èª­ã¿è¾¼ã¾ãšã€çŠ¶æ…‹ã®ã¿æº–å‚™
      Object.keys(this.availableInstruments).forEach(key => {
        this.loadingStatus[key] = { status: 'not-loaded', progress: 0 };
      });
      
      this.initialized = true;
      console.log('RealisticToneEngine: Initialized successfully (on-demand mode)');
      
      // åˆæœŸåŒ–å®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆ
      if (typeof window !== 'undefined') {
        window.dispatchEvent(new CustomEvent('musicEngineReady', {
          detail: { engine: this, mode: 'on-demand' }
        }));
      }
      
    } catch (error) {
      console.error('Failed to initialize RealisticToneEngine:', error);
      this.initialized = false;
      throw error;
    }
  }

  /**
   * æ¥½å™¨ã®ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰èª­ã¿è¾¼ã¿
   */
  async loadInstrumentOnDemand(instrumentKey) {
    // æ—¢ã«èª­ã¿è¾¼ã¿æ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if (this.samplers[instrumentKey] && this.loadingStatus[instrumentKey]?.status === 'loaded') {
      console.log(`Instrument ${instrumentKey} already loaded`);
      return this.samplers[instrumentKey];
    }

    console.log(`Loading instrument on-demand: ${instrumentKey}`);
    this.loadingStatus[instrumentKey] = { status: 'loading', progress: 0 };

    try {
      // SampleLibraryãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆ
      if (typeof SampleLibrary !== 'undefined') {
        const sampler = await this.loadWithSampleLibrary(instrumentKey);
        if (sampler) {
          this.samplers[instrumentKey] = sampler;
          this.loadingStatus[instrumentKey] = { status: 'loaded', progress: 100 };
          console.log(`âœ“ Successfully loaded real instrument: ${instrumentKey}`);
          return sampler;
        }
      }

      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼ã‚’ä½¿ç”¨
      console.log(`Using fallback synthesizer for: ${instrumentKey}`);
      const fallbackSampler = this.createFallbackInstrument(instrumentKey);
      this.samplers[instrumentKey] = fallbackSampler;
      this.loadingStatus[instrumentKey] = { status: 'fallback', progress: 100 };
      return fallbackSampler;

    } catch (error) {
      console.error(`Failed to load instrument ${instrumentKey}:`, error);
      
      // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½œæˆ
      const fallbackSampler = this.createFallbackInstrument(instrumentKey);
      this.samplers[instrumentKey] = fallbackSampler;
      this.loadingStatus[instrumentKey] = { status: 'fallback', progress: 100 };
      return fallbackSampler;
    }
  }

  /**
   * SampleLibraryã‚’ä½¿ç”¨ã—ãŸæ¥½å™¨èª­ã¿è¾¼ã¿
   */
  async loadWithSampleLibrary(instrumentKey) {
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error(`Load timeout for ${instrumentKey}`));
      }, 10000); // 10ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

      try {
        const instruments = SampleLibrary.load({
          instruments: [instrumentKey],
          baseUrl: "https://cdn.jsdelivr.net/gh/nbrosowsky/tonejs-instruments/samples/",
          onload: () => {
            clearTimeout(timeout);
            const sampler = instruments[instrumentKey];
            if (sampler) {
              sampler.toDestination();
              resolve(sampler);
            } else {
              reject(new Error(`Sampler not found for ${instrumentKey}`));
            }
          },
          onerror: (error) => {
            clearTimeout(timeout);
            reject(error);
          }
        });

        // å³åº§ã«åˆ©ç”¨å¯èƒ½ãªå ´åˆ
        if (instruments && instruments[instrumentKey]) {
          clearTimeout(timeout);
          instruments[instrumentKey].toDestination();
          resolve(instruments[instrumentKey]);
        }
      } catch (error) {
        clearTimeout(timeout);
        reject(error);
      }
    });
  }

  /**
   * ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¥½å™¨ã®ä½œæˆ
   */
  createFallbackInstrument(instrumentKey) {
    const category = this.availableInstruments[instrumentKey]?.category || 'keyboard';
    
    switch (category) {
      case 'keyboard':
        return new Tone.Synth({
          oscillator: { type: 'triangle' },
          envelope: { attack: 0.1, decay: 0.3, sustain: 0.3, release: 1 }
        }).toDestination();
        
      case 'strings':
        if (instrumentKey.includes('bass') || instrumentKey === 'contrabass') {
          return new Tone.MonoSynth({
            oscillator: { type: 'sawtooth' },
            filter: { frequency: 200, Q: 2 },
            envelope: { attack: 0.1, decay: 0.3, sustain: 0.7, release: 0.8 }
          }).toDestination();
        } else {
          return new Tone.Synth({
            oscillator: { type: 'sawtooth' },
            envelope: { attack: 0.2, decay: 0.1, sustain: 0.8, release: 0.5 }
          }).toDestination();
        }
        
      case 'wind':
        return new Tone.Synth({
          oscillator: { type: 'sine' },
          envelope: { attack: 0.1, decay: 0.2, sustain: 0.6, release: 0.4 }
        }).toDestination();
        
      case 'bass':
        return new Tone.MonoSynth({
          oscillator: { type: 'sawtooth' },
          filter: { frequency: 150, Q: 2, type: 'lowpass' },
          envelope: { attack: 0.1, decay: 0.3, sustain: 0.7, release: 0.8 }
        }).toDestination();
        
      case 'percussion':
        return new Tone.MembraneSynth({
          pitchDecay: 0.05,
          octaves: 10,
          oscillator: { type: 'sine' },
          envelope: { attack: 0.001, decay: 0.4, sustain: 0.01, release: 1.4 }
        }).toDestination();
        
      default:
        return new Tone.Synth().toDestination();
    }
  }

  /**
   * è¤‡æ•°æ¥½å™¨ã®ä¸¦åˆ—èª­ã¿è¾¼ã¿
   */
  async loadMultipleInstruments(instrumentKeys, onProgress = null) {
    console.log(`Loading multiple instruments: ${instrumentKeys.join(', ')}`);
    
    const loadPromises = instrumentKeys.map(async (instrumentKey, index) => {
      try {
        const sampler = await this.loadInstrumentOnDemand(instrumentKey);
        if (onProgress) {
          onProgress(instrumentKey, index + 1, instrumentKeys.length);
        }
        return { instrumentKey, sampler, success: true };
      } catch (error) {
        console.error(`Failed to load ${instrumentKey}:`, error);
        if (onProgress) {
          onProgress(instrumentKey, index + 1, instrumentKeys.length, error);
        }
        return { instrumentKey, sampler: null, success: false, error };
      }
    });

    const results = await Promise.allSettled(loadPromises);
    return results.map(result => result.value || result.reason);
  }

  /**
   * éŸ³æ¥½ç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³å‡¦ç†
   */
  async generateMusic(settings) {
    try {
      console.log('Generating music with settings:', settings);

      if (!this.initialized) {
        throw new Error('Engine not initialized');
      }

      // Tone.jsã®é–‹å§‹
      if (Tone.context.state === 'suspended') {
        await Tone.start();
      }

      // è¨­å®šã®è§£æ
      const params = this.parseSettings(settings);
      console.log('Parsed parameters:', params);

      // å¿…è¦ãªæ¥½å™¨ã‚’ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰èª­ã¿è¾¼ã¿
      console.log('Loading required instruments...');
      await this.loadMultipleInstruments(params.instruments, (instrument, loaded, total) => {
        console.log(`Loading progress: ${instrument} (${loaded}/${total})`);
      });

      // æ¥½æ›²æ§‹é€ ã®ä½œæˆ
      const composition = this.createComposition(params);
      console.log('Created composition:', composition);

      // ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
      const audioData = await this.renderComposition(composition, params);
      
      this.currentComposition = {
        composition,
        params,
        audioData,
        timestamp: Date.now()
      };

      return {
        success: true,
        audioData,
        composition,
        waveform: this.generateWaveform(audioData),
        metadata: {
          duration: params.duration,
          tempo: params.tempo,
          key: params.key,
          scale: params.scale,
          instruments: params.instruments,
          genre: params.genre
        }
      };

    } catch (error) {
      console.error('Music generation failed:', error);
      return {
        success: false,
        error: error.message,
        fallback: this.generateSimpleFallback()
      };
    }
  }

  /**
   * è¨­å®šã®è§£æ
   */
  parseSettings(settings) {
    const defaults = {
      genre: 'pop',
      mood: 'happy',
      tempo: 120,
      duration: 30,
      key: 'C',
      scale: 'major',
      instruments: ['piano', 'guitar-acoustic', 'bass-electric']
    };

    // ã‚¸ãƒ£ãƒ³ãƒ«ãƒ™ãƒ¼ã‚¹ã®è‡ªå‹•è¨­å®š
    const genreData = this.genres[settings.genre] || this.genres.pop;
    
    return {
      genre: settings.genre || defaults.genre,
      mood: settings.mood || defaults.mood,
      tempo: settings.tempo || genreData.tempo,
      duration: parseInt(settings.duration) || defaults.duration,
      key: settings.key || defaults.key,
      scale: settings.scale || genreData.scale,
      instruments: settings.instruments || genreData.instruments,
      progression: genreData.progression,
      structure: this.generateStructure(settings.duration || defaults.duration)
    };
  }

  /**
   * æ¥½æ›²æ§‹é€ ã®ç”Ÿæˆ
   */
  generateStructure(duration) {
    const sections = [];
    
    if (duration <= 15) {
      sections.push({ type: 'verse', start: 0, duration: duration });
    } else if (duration <= 30) {
      sections.push({ type: 'intro', start: 0, duration: 4 });
      sections.push({ type: 'verse', start: 4, duration: duration - 8 });
      sections.push({ type: 'outro', start: duration - 4, duration: 4 });
    } else {
      sections.push({ type: 'intro', start: 0, duration: 4 });
      sections.push({ type: 'verse', start: 4, duration: 8 });
      sections.push({ type: 'chorus', start: 12, duration: 8 });
      sections.push({ type: 'verse', start: 20, duration: 8 });
      sections.push({ type: 'outro', start: duration - 2, duration: 2 });
    }
    
    return sections;
  }

  /**
   * ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³ã®ä½œæˆ
   */
  createComposition(params) {
    const scale = this.scales[params.scale] || this.scales.major;
    const progression = this.chordProgressions[params.progression] || this.chordProgressions.pop;
    
    const composition = {
      tempo: params.tempo,
      key: params.key,
      scale: scale,
      progression: progression,
      tracks: []
    };

    // å„æ¥½å™¨ã®ãƒˆãƒ©ãƒƒã‚¯ã‚’ä½œæˆ
    params.instruments.forEach((instrument, index) => {
      if (this.samplers[instrument]) {
        const track = this.createTrack(instrument, scale, progression, params, index);
        composition.tracks.push(track);
      }
    });

    return composition;
  }

  /**
   * ãƒˆãƒ©ãƒƒã‚¯ã®ä½œæˆ
   */
  createTrack(instrument, scale, progression, params, trackIndex) {
    const track = {
      instrument: instrument,
      sampler: this.samplers[instrument],
      notes: [],
      pattern: this.getInstrumentPattern(instrument, params.genre)
    };

    // æ¥½å™¨ã®å½¹å‰²ã«å¿œã˜ã¦ãƒ¡ãƒ­ãƒ‡ã‚£ã‚’ç”Ÿæˆ
    const category = this.availableInstruments[instrument]?.category;
    switch (category) {
      case 'keyboard':
        track.notes = this.generateMelody(scale, params.duration, params.tempo);
        break;
      case 'strings':
        if (instrument.includes('bass') || instrument === 'contrabass') {
          track.notes = this.generateBassLine(scale, params.duration, params.tempo);
        } else {
          track.notes = this.generateHarmony(scale, params.duration, params.tempo);
        }
        break;
      case 'bass':
        track.notes = this.generateBassLine(scale, params.duration, params.tempo);
        break;
      case 'wind':
        track.notes = this.generateMelody(scale, params.duration, params.tempo, true);
        break;
      default:
        track.notes = this.generateSimplePattern(scale, params.duration, params.tempo);
    }

    return track;
  }

  /**
   * ãƒ¡ãƒ­ãƒ‡ã‚£ã®ç”Ÿæˆ
   */
  generateMelody(scale, duration, tempo, isLead = false) {
    const notes = [];
    const noteInterval = 60 / tempo;
    const totalBeats = Math.floor(duration / noteInterval);
    
    let currentNote = isLead ? scale[4] : scale[2];
    
    for (let beat = 0; beat < totalBeats; beat++) {
      const time = beat * noteInterval;
      
      // ãƒ¡ãƒ­ãƒ‡ã‚£ã®å‹•ãã‚’ç”Ÿæˆ
      const direction = Math.random() - 0.5;
      let nextIndex = scale.indexOf(currentNote % 12);
      
      if (direction > 0.2 && nextIndex < scale.length - 1) {
        nextIndex++;
      } else if (direction < -0.2 && nextIndex > 0) {
        nextIndex--;
      }
      
      currentNote = scale[nextIndex] + Math.floor(currentNote / 12) * 12;
      
      // éŸ³åŸŸåˆ¶é™
      if (currentNote < 48) currentNote += 12;
      if (currentNote > 84) currentNote -= 12;
      
      const noteName = this.midiToNoteName(currentNote);
      const noteDuration = this.getNoteDuration(beat, tempo);
      
      notes.push({
        time: time,
        note: noteName,
        duration: noteDuration,
        velocity: 0.7 + Math.random() * 0.3
      });
    }
    
    return notes;
  }

  /**
   * ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ç”Ÿæˆ
   */
  generateBassLine(scale, duration, tempo) {
    const notes = [];
    const noteInterval = 60 / tempo;
    const totalBeats = Math.floor(duration / noteInterval);
    
    const bassNotes = scale.map(note => note + 36);
    
    for (let beat = 0; beat < totalBeats; beat += 2) {
      const time = beat * noteInterval;
      const rootNote = bassNotes[0];
      const fifthNote = bassNotes[4 % bassNotes.length];
      
      const note = (beat % 8 < 4) ? rootNote : fifthNote;
      const noteName = this.midiToNoteName(note);
      
      notes.push({
        time: time,
        note: noteName,
        duration: noteInterval * 1.5,
        velocity: 0.8
      });
    }
    
    return notes;
  }

  /**
   * ãƒãƒ¼ãƒ¢ãƒ‹ãƒ¼ã®ç”Ÿæˆ
   */
  generateHarmony(scale, duration, tempo) {
    const notes = [];
    const chordInterval = (60 / tempo) * 4;
    const totalChords = Math.ceil(duration / chordInterval);
    
    for (let chord = 0; chord < totalChords; chord++) {
      const time = chord * chordInterval;
      const chordTones = [
        scale[0] + 60,
        scale[2] + 60,
        scale[4] + 60
      ];
      
      chordTones.forEach((tone, index) => {
        const noteName = this.midiToNoteName(tone);
        notes.push({
          time: time + index * 0.1,
          note: noteName,
          duration: chordInterval - 0.2,
          velocity: 0.5
        });
      });
    }
    
    return notes;
  }

  /**
   * ã‚·ãƒ³ãƒ—ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç”Ÿæˆ
   */
  generateSimplePattern(scale, duration, tempo) {
    const notes = [];
    const noteInterval = 60 / tempo;
    const patternLength = 4;
    
    for (let i = 0; i < duration / noteInterval; i += patternLength) {
      const baseTime = i * noteInterval;
      const note = scale[i % scale.length] + 60;
      const noteName = this.midiToNoteName(note);
      
      notes.push({
        time: baseTime,
        note: noteName,
        duration: noteInterval,
        velocity: 0.6
      });
    }
    
    return notes;
  }

  /**
   * MIDIãƒãƒ¼ãƒˆç•ªå·ã‚’éŸ³åã«å¤‰æ›
   */
  midiToNoteName(midi) {
    const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
    const octave = Math.floor(midi / 12) - 1;
    const note = noteNames[midi % 12];
    return `${note}${octave}`;
  }

  /**
   * éŸ³ç¬¦ã®é•·ã•ã‚’æ±ºå®š
   */
  getNoteDuration(beat, tempo) {
    const base = 60 / tempo;
    const patterns = [base, base / 2, base * 1.5, base / 4];
    return patterns[beat % patterns.length];
  }

  /**
   * æ¥½å™¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å–å¾—
   */
  getInstrumentPattern(instrument, genre) {
    const patterns = {
      'piano': { attack: 0.1, rhythm: 'melody' },
      'guitar-acoustic': { attack: 0.05, rhythm: 'strum' },
      'bass-electric': { attack: 0.1, rhythm: 'bass' },
      'violin': { attack: 0.2, rhythm: 'legato' }
    };
    return patterns[instrument] || patterns['piano'];
  }

  /**
   * ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
   */
  async renderComposition(composition, params) {
    try {
      console.log('Rendering composition...');
      
      // Tone.jsã®éŒ²éŸ³ã‚’é–‹å§‹
      const recorder = new Tone.Recorder();
      Tone.Destination.connect(recorder);
      
      await recorder.start();
      
      // å…¨ãƒˆãƒ©ãƒƒã‚¯ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
      composition.tracks.forEach(track => {
        this.scheduleTrack(track);
      });
      
      // å†ç”Ÿé–‹å§‹
      Tone.Transport.bpm.value = composition.tempo;
      Tone.Transport.start();
      
      // éŒ²éŸ³å®Œäº†ã¾ã§å¾…æ©Ÿ
      const playbackDuration = params.duration * 1000 + 1000;
      await new Promise(resolve => setTimeout(resolve, playbackDuration));
      
      // åœæ­¢ã¨éŒ²éŸ³çµ‚äº†
      Tone.Transport.stop();
      Tone.Transport.cancel();
      
      const recording = await recorder.stop();
      
      console.log('Rendering completed');
      return recording;
      
    } catch (error) {
      console.error('Rendering failed:', error);
      throw error;
    }
  }

  /**
   * ãƒˆãƒ©ãƒƒã‚¯ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
   */
  scheduleTrack(track) {
    track.notes.forEach(noteData => {
      Tone.Transport.schedule((time) => {
        if (track.sampler && track.sampler.triggerAttackRelease) {
          track.sampler.triggerAttackRelease(
            noteData.note,
            noteData.duration,
            time,
            noteData.velocity
          );
        }
      }, noteData.time);
    });
  }

  /**
   * æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
   */
  generateWaveform(audioData) {
    if (!audioData) return [];
    
    try {
      const samples = 100;
      const waveform = [];
      
      for (let i = 0; i < samples; i++) {
        const amplitude = Math.sin(i * 0.1) * 0.5 + Math.random() * 0.3;
        waveform.push(Math.max(-1, Math.min(1, amplitude)));
      }
      
      return waveform;
    } catch (error) {
      console.error('Waveform generation failed:', error);
      return [];
    }
  }

  /**
   * ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯éŸ³æ¥½
   */
  generateSimpleFallback() {
    return {
      notes: ['C4', 'D4', 'E4', 'F4', 'G4'],
      message: 'ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒ­ãƒ‡ã‚£ã‚’ç”Ÿæˆã—ã¾ã—ãŸ'
    };
  }

  /**
   * æ¥½å™¨èª­ã¿è¾¼ã¿çŠ¶æ³ã®å–å¾—
   */
  getLoadingStatus() {
    return this.loadingStatus;
  }

  /**
   * åˆ©ç”¨å¯èƒ½æ¥½å™¨ãƒªã‚¹ãƒˆã®å–å¾—
   */
  getAvailableInstrumentsList() {
    return Object.keys(this.availableInstruments).map(key => ({
      key: key,
      name: this.availableInstruments[key]?.name || key,
      category: this.availableInstruments[key]?.category || 'other',
      status: this.loadingStatus[key]?.status || 'not-loaded'
    }));
  }

  /**
   * åˆ©ç”¨å¯èƒ½ãªæ¥½å™¨ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆUIç”¨ï¼‰
   */
  getAvailableInstruments() {
    const instrumentData = this.getAvailableInstrumentsList();
    return instrumentData.map(key => {
      const info = this.availableInstruments[key];
      return {
        id: key,
        name: info.name,
        category: info.category,
        emoji: this.getInstrumentEmoji(key),
        default: this.isDefaultInstrument(key)
      };
    });
  }

  /**
   * æ¥½å™¨ã®çµµæ–‡å­—ã‚’å–å¾—
   */
  getInstrumentEmoji(key) {
    const emojiMap = {
      'piano': 'ğŸ¹',
      'guitar-acoustic': 'ğŸ¸',
      'guitar-electric': 'ğŸ¸',
      'bass-electric': 'ğŸ¸',
      'violin': 'ğŸ»',
      'cello': 'ğŸ»',
      'flute': 'ğŸº',
      'saxophone': 'ğŸ·',
      'trumpet': 'ğŸº',
      'drums': 'ğŸ¥',
      'organ': 'ğŸ¹'
    };
    return emojiMap[key] || 'ğŸµ';
  }

  /**
   * ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¥½å™¨ã‹ã©ã†ã‹åˆ¤å®š
   */
  isDefaultInstrument(key) {
    const defaultInstruments = ['piano', 'guitar-acoustic', 'bass-electric'];
    return defaultInstruments.includes(key);
  }

  /**
   * ç¾åœ¨ã®ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³ã®å†ç”Ÿ
   */
  async playComposition(composition) {
    if (!composition || !this.initialized) {
      throw new Error('No composition to play or engine not initialized');
    }

    try {
      Tone.Transport.cancel();
      
      composition.tracks.forEach(track => {
        this.scheduleTrack(track);
      });
      
      Tone.Transport.bpm.value = composition.tempo;
      Tone.Transport.start();
      
      return true;
    } catch (error) {
      console.error('Playback failed:', error);
      return false;
    }
  }

  /**
   * éŸ³å£°å†ç”Ÿ
   */
  async playAudio(audioBuffer) {
    try {
      if (Tone.context.state === 'suspended') {
        await Tone.start();
      }

      // æ—¢å­˜ã®å†ç”Ÿã‚’åœæ­¢
      if (this.currentPlayer) {
        this.currentPlayer.stop();
        this.currentPlayer.dispose();
      }

      // æ–°ã—ã„ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½œæˆ
      this.currentPlayer = new Tone.Player(audioBuffer).toDestination();
      await this.currentPlayer.start();
      
      return true;
    } catch (error) {
      console.error('Audio playback failed:', error);
      throw error;
    }
  }

  /**
   * éŸ³å£°ä¸€æ™‚åœæ­¢
   */
  async pauseAudio() {
    if (this.currentPlayer) {
      this.currentPlayer.stop();
    }
  }

  /**
   * éŸ³å£°åœæ­¢
   */
  async stopAudio() {
    if (this.currentPlayer) {
      this.currentPlayer.stop();
      this.currentPlayer.dispose();
      this.currentPlayer = null;
    }
  }

  /**
   * WAVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
   */
  async downloadAudio(audioBuffer, filename = 'generated-music.wav') {
    try {
      // AudioBuffer ã‚’ WAV ã¨ã—ã¦å¤‰æ›
      const wavBuffer = this.audioBufferToWav(audioBuffer);
      
      // ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ
      const blob = new Blob([wavBuffer], { type: 'audio/wav' });
      const url = URL.createObjectURL(blob);
      
      const link = document.createElement('a');
      link.href = url;
      link.download = filename;
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
      
      URL.revokeObjectURL(url);
    } catch (error) {
      console.error('Download failed:', error);
      throw error;
    }
  }

  /**
   * AudioBuffer ã‚’ WAV ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
   */
  audioBufferToWav(audioBuffer) {
    const length = audioBuffer.length;
    const channels = audioBuffer.numberOfChannels;
    const sampleRate = audioBuffer.sampleRate;
    const arrayBuffer = new ArrayBuffer(44 + length * channels * 2);
    const view = new DataView(arrayBuffer);

    // WAVãƒ˜ãƒƒãƒ€ãƒ¼ã®æ›¸ãè¾¼ã¿
    const writeString = (offset, string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };

    writeString(0, 'RIFF');
    view.setUint32(4, 36 + length * channels * 2, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, channels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * channels * 2, true);
    view.setUint16(32, channels * 2, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, length * channels * 2, true);

    // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿
    let offset = 44;
    for (let i = 0; i < length; i++) {
      for (let channel = 0; channel < channels; channel++) {
        const sample = Math.max(-1, Math.min(1, audioBuffer.getChannelData(channel)[i]));
        view.setInt16(offset, sample * 0x7FFF, true);
        offset += 2;
      }
    }

    return arrayBuffer;
  }
}

// ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«å…¬é–‹
window.RealisticToneEngine = RealisticToneEngine;
