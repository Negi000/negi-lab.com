/**
 * éŸ³æ¥½ç”Ÿæˆã‚³ã‚¢æ©Ÿèƒ½ - é«˜åº¦éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ç‰ˆ
 * Web Audio APIå®Œå…¨æ´»ç”¨ã«ã‚ˆã‚‹é«˜å“è³ªæ¥½å™¨éŸ³è‰²ç”Ÿæˆ
 */

class MusicGenerator {
  constructor() {
    this.audioContext = null;
    this.advancedEngine = null;
    this.isGenerating = false;
    this.currentMusic = null;
    this.isPlaying = false;
    this.activeNotes = [];
    this.scheduledNotes = [];
    this.isInitialized = false;
    
    // éåŒæœŸåˆæœŸåŒ–ã‚’å®Ÿè¡Œ
    this.initialize();
  }

  async initialize() {
    try {
      await this.initializeAudioContext();
      this.isInitialized = true;
      console.log('MusicGenerator fully initialized');
    } catch (error) {
      console.error('MusicGenerator initialization failed:', error);
    }
  }

  async initializeAudioContext() {
    try {
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
      
      // é«˜åº¦éŸ³éŸ¿ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
      this.advancedEngine = new AdvancedAudioEngine(this.audioContext);
      
      console.log('Advanced audio engine initialized successfully');
      console.log('Sample rate:', this.audioContext.sampleRate);
    } catch (error) {
      console.error('Advanced audio engine initialization failed:', error);
    }
  }

  async waitForInitialization() {
    const maxWait = 5000; // æœ€å¤§5ç§’å¾…æ©Ÿ
    const startTime = Date.now();
    
    while (!this.isInitialized && (Date.now() - startTime) < maxWait) {
      await new Promise(resolve => setTimeout(resolve, 100));
    }
    
    if (!this.isInitialized) {
      throw new Error('MusicGenerator initialization timeout');
    }
  }

  // ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤ï¼ˆå…ˆã«å®šç¾©ï¼‰
  getTempoValue(tempo) {
    // ãƒ†ãƒ³ãƒç¯„å›²å†…ã§ãƒ©ãƒ³ãƒ€ãƒ ãªå€¤ã‚’ç”Ÿæˆ
    const tempoRanges = {
      'slow': { min: 60, max: 80 },
      'medium': { min: 100, max: 140 },
      'fast': { min: 130, max: 160 }
    };
    
    const range = tempoRanges[tempo] || tempoRanges['medium'];
    const randomTempo = Math.floor(Math.random() * (range.max - range.min + 1)) + range.min;
    
    console.log(`ğŸ¥ Selected tempo for ${tempo}: ${randomTempo} BPM`);
    return randomTempo;
  }

  getDurationValue(duration) {
    const durationMap = {
      'short': 15,
      'medium': 30,
      'long': 60
    };
    return durationMap[duration] || 30;
  }

  getKeyFromMood(mood) {
    // ãƒ ãƒ¼ãƒ‰ã”ã¨ã«è¤‡æ•°ã®ã‚­ãƒ¼ã‚’ç”¨æ„ã—ã¦ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
    const keyOptions = {
      'calm': ['C', 'F', 'G', 'Am', 'Dm'],
      'energetic': ['G', 'D', 'E', 'A', 'Em'],
      'dramatic': ['Dm', 'Gm', 'Am', 'Em', 'Bm'],
      'peaceful': ['F', 'C', 'Bb', 'Dm', 'Gm'],
      'uplifting': ['D', 'A', 'E', 'G', 'C'],
      'melancholic': ['Am', 'Em', 'Dm', 'Gm', 'Fm']
    };
    
    const options = keyOptions[mood] || keyOptions['calm'];
    const selectedKey = options[Math.floor(Math.random() * options.length)];
    
    console.log(`ğŸµ Selected key for ${mood}: ${selectedKey}`);
    return selectedKey;
  }

  getScaleFromGenre(genre) {
    const scaleMap = {
      'classical': 'major',
      'jazz': 'major',
      'rock': 'minor',
      'electronic': 'minor',
      'ambient': 'major',
      'cinematic': 'minor'
    };
    return scaleMap[genre] || 'major';
  }

  getScaleNotes(key, scaleType) {
    const chromatic = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
    const keyIndex = chromatic.indexOf(key.replace('m', ''));
    
    const scaleIntervals = {
      'major': [0, 2, 4, 5, 7, 9, 11],
      'minor': [0, 2, 3, 5, 7, 8, 10]
    };
    
    const intervals = scaleIntervals[scaleType] || scaleIntervals['major'];
    return intervals.map(interval => chromatic[(keyIndex + interval) % 12]);
  }

  noteToFrequency(note, octave) {
    const noteFrequencies = {
      'C': 261.63, 'C#': 277.18, 'D': 293.66, 'D#': 311.13,
      'E': 329.63, 'F': 349.23, 'F#': 369.99, 'G': 392.00,
      'G#': 415.30, 'A': 440.00, 'A#': 466.16, 'B': 493.88
    };
    const baseFreq = noteFrequencies[note] || 440;
    return baseFreq * Math.pow(2, octave - 4);
  }

  async generateMusic(settings) {
    if (this.isGenerating) return null;
    
    // åˆæœŸåŒ–ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
    if (!this.isInitialized) {
      console.log('Waiting for MusicGenerator initialization...');
      await this.waitForInitialization();
    }
    
    // ã‚¨ãƒ³ã‚¸ãƒ³ã®å­˜åœ¨ã‚’ç¢ºèª
    if (!this.advancedEngine) {
      console.error('Advanced audio engine not available');
      throw new Error('Audio engine initialization failed');
    }
    
    this.isGenerating = true;
    console.log('ğŸµ Generating music with detailed settings:', {
      genre: settings.genre,
      mood: settings.mood,
      tempo: settings.tempo,
      duration: settings.duration,
      instruments: settings.instruments,
      complexity: settings.complexity,
      volume: settings.volume,
      loop: settings.loop
    });
    
    try {
      this.notifyProgress(0, 'Analyzing musical preferences...');
      
      // AudioContextã®å†é–‹ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
      if (this.audioContext && this.audioContext.state === 'suspended') {
        await this.audioContext.resume();
      }
      
      // éŸ³æ¥½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—
      const params = this.calculateMusicParameters(settings);
      console.log('ğŸ¼ Calculated parameters with style differences:', {
        originalTempo: params.tempo,
        adjustedTempo: params.adjustedTempo,
        key: params.key,
        scale: params.scale,
        genre: params.genre,
        mood: params.mood,
        complexity: params.complexity,
        volume: params.volume,
        instruments: params.instruments
      });
      
      this.notifyProgress(25, `Composing ${params.genre} melody in ${params.key} ${params.scale} (${params.complexity})...`);
      
      // é«˜åº¦ãªãƒ¡ãƒ­ãƒ‡ã‚£ç”Ÿæˆ
      const melody = this.generateAdvancedMelody(params);
      console.log('ğŸ¹ Genre-specific melody generated:', {
        noteCount: melody.notes.length,
        instrument: melody.instrument,
        scale: melody.scale,
        firstNote: melody.notes[0] ? `${melody.notes[0].note}${melody.notes[0].octave}` : 'none',
        avgVelocity: melody.notes.reduce((sum, note) => sum + note.velocity, 0) / melody.notes.length
      });
      
      this.notifyProgress(50, `Creating ${params.genre} harmony with ${params.mood} characteristics...`);
      
      // é«˜åº¦ãªãƒãƒ¼ãƒ¢ãƒ‹ãƒ¼ç”Ÿæˆ
      const harmony = this.generateAdvancedHarmony(params);
      console.log('ğŸº Mood-specific harmony generated:', {
        chordCount: harmony.chords.length,
        instrument: harmony.instrument,
        progression: harmony.progression,
        firstChord: harmony.chords[0] ? harmony.chords[0].symbol : 'none'
      });
      
      this.notifyProgress(75, `Synthesizing with ${params.complexity} complexity and ${params.instruments.join(', ')} instruments...`);
      
      // é«˜å“è³ªéŸ³éŸ¿åˆæˆ
      const audioData = await this.synthesizeWithAdvancedEngine(melody, harmony, params);
      
      // å®‰å…¨ãªæœ€å¤§æŒ¯å¹…è¨ˆç®—ï¼ˆã‚¹ã‚¿ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–ï¼‰
      let maxAmplitude = 0;
      for (let i = 0; i < audioData.length; i++) {
        const abs = Math.abs(audioData[i]);
        if (abs > maxAmplitude) {
          maxAmplitude = abs;
        }
      }
      
      console.log('ğŸ”Š Audio synthesis complete:', {
        length: audioData.length,
        duration: audioData.length / this.audioContext.sampleRate,
        maxAmplitude: maxAmplitude,
        complexity: params.complexity,
        volume: params.volume
      });
      
      this.notifyProgress(100, `${params.genre}/${params.mood} music ready!`);
      
      const musicData = {
        audioData: audioData,
        waveform: this.generateWaveform(audioData),
        melody: melody,
        harmony: harmony,
        params: params,
        metadata: {
          duration: params.duration,
          tempo: params.adjustedTempo || params.tempo,
          key: params.key,
          genre: settings.genre || 'ambient',
          mood: settings.mood || 'calm',
          instruments: settings.instruments || ['piano'],
          complexity: settings.complexity || 'moderate',
          volume: settings.volume || 0.7,
          generatedAt: new Date().toISOString(),
          engine: 'AdvancedAudioEngine',
          quality: 'Professional',
          settingsHash: this.generateSettingsHash(settings)
        }
      };
      
      this.currentMusic = musicData;
      console.log('âœ… Music generation complete with unique characteristics for:', settings.genre, settings.mood, settings.complexity);
      return musicData;
      
    } catch (error) {
      console.error('âŒ High-quality music generation failed:', error);
      return this.generateFallbackMusic(settings);
    } finally {
      this.isGenerating = false;
    }
  }

  generateAdvancedMelody(params) {
    const melody = {
      notes: [],
      instrument: this.selectMelodyInstrument(params.instruments),
      scale: this.getScaleFromGenre(params.genre)
    };

    const scaleNotes = this.getScaleNotes(params.key, melody.scale);
    
    // èª¿æ•´ã•ã‚ŒãŸãƒ†ãƒ³ãƒã‚’ä½¿ç”¨
    const actualTempo = params.adjustedTempo || params.tempo;
    const beatDuration = 60 / actualTempo; // 1æ‹ã®é•·ã•ï¼ˆç§’ï¼‰
    const totalBeats = Math.floor(params.duration / beatDuration);
    
    console.log(`ğŸ¼ Generating melody for ${params.genre}/${params.mood}: ${totalBeats} beats, beat duration: ${beatDuration.toFixed(3)}s`);
    console.log(`ğŸµ Key: ${params.key}, Scale: ${melody.scale}, Instrument: ${melody.instrument}, Tempo: ${actualTempo}, Complexity: ${params.complexity}`);
    
    let currentTime = 0;
    let currentScaleIndex = 0; // ãƒ«ãƒ¼ãƒˆéŸ³ã‹ã‚‰é–‹å§‹
    
    // ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã®éŸ³æ¥½çš„ç‰¹å¾´ã‚’åæ˜ 
    const genreCharacteristics = this.getGenreCharacteristics(params.genre);
    const moodCharacteristics = this.getMoodCharacteristics(params.mood);
    
    // è¤‡é›‘ã•ã«ã‚ˆã‚‹éŸ³æ¥½çš„èª¿æ•´
    const complexityFactor = this.getComplexityFactor(params.complexity);
    
    // ã‚·ãƒ³ãƒ—ãƒ«ã§éŸ³æ¥½çš„ãªãƒ¡ãƒ­ãƒ‡ã‚£ã‚’ç”Ÿæˆ
    for (let beat = 0; beat < totalBeats; beat++) {
      // 4æ‹ã”ã¨ã«åŒºåˆ‡ã‚‹ï¼ˆå°ç¯€ï¼‰
      const measurePosition = beat % 4;
      
      // ã‚¸ãƒ£ãƒ³ãƒ«ã€ãƒ ãƒ¼ãƒ‰ã€è¤‡é›‘ã•ã«åŸºã¥ãéŸ³ç¬¦ã®é•·ã•ã‚’æ±ºå®š
      let noteDuration = this.calculateGenreBasedDuration(beatDuration, measurePosition, genreCharacteristics);
      noteDuration *= complexityFactor.durationMultiplier;
      
      // ã‚¹ã‚±ãƒ¼ãƒ«å†…ã®éŸ³ç¬¦ã‚’éŸ³æ¥½çš„ã«é¸æŠ
      currentScaleIndex = this.selectMelodyNote(
        measurePosition, 
        currentScaleIndex, 
        scaleNotes.length, 
        genreCharacteristics,
        moodCharacteristics,
        complexityFactor
      );
      
      const note = scaleNotes[currentScaleIndex];
      const octave = this.selectMelodicOctave(note, params.genre, Math.floor(beat / 4), params.mood);
      const frequency = this.noteToFrequency(note, octave);
      
      // ãƒ ãƒ¼ãƒ‰ã«åŸºã¥ããƒ™ãƒ­ã‚·ãƒ†ã‚£ã‚’éŸ³æ¥½çš„ã«è¨­å®š
      let velocity = this.calculateMoodBasedVelocity(measurePosition, moodCharacteristics);
      velocity *= params.volume; // ãƒœãƒªãƒ¥ãƒ¼ãƒ è¨­å®šã‚’åæ˜ 
      
      melody.notes.push({
        note: note,
        octave: octave,
        frequency: frequency,
        startTime: currentTime,
        duration: noteDuration,
        velocity: velocity,
        measurePosition: measurePosition,
        genre: params.genre,
        mood: params.mood,
        complexity: params.complexity
      });
      
      currentTime += noteDuration;
      
      // ã‚¸ãƒ£ãƒ³ãƒ«ã¨è¤‡é›‘ã•ã«åŸºã¥ãä¼‘ç¬¦ã‚’æ™‚ã€…æŒ¿å…¥
      if (this.shouldInsertRest(measurePosition, genreCharacteristics, complexityFactor)) {
        currentTime += beatDuration * 0.5;
      }
    }

    console.log(`âœ… Generated ${melody.notes.length} melody notes over ${currentTime.toFixed(2)}s`);
    return melody;
  }

  generateMelodicPhrases(params, totalNotes) {
    const phrases = [];
    const phraseLengths = this.getPhraseStructure(params.genre);
    
    let remainingNotes = totalNotes;
    
    phraseLengths.forEach(length => {
      if (remainingNotes <= 0) return;
      
      const phraseNotes = Math.min(length, remainingNotes);
      const phrase = this.createMelodicPhrase(phraseNotes, params);
      phrases.push(phrase);
      remainingNotes -= phraseNotes;
    });
    
    return phrases;
  }

  createMelodicPhrase(noteCount, params) {
    const phrase = { notes: [] };
    const baseDuration = 60 / params.tempo;
    
    for (let i = 0; i < noteCount; i++) {
      const position = i / noteCount;
      
      phrase.notes.push({
        duration: this.calculateNoteDuration(baseDuration, params, position),
        velocity: this.calculateNoteVelocity(params, position, i),
        expression: this.calculateNoteExpression(params, position)
      });
    }
    
    return phrase;
  }

  generateAdvancedHarmony(params) {
    const harmony = {
      chords: [],
      instrument: this.selectHarmonyInstrument(params.instruments),
      progression: this.selectAdvancedProgression(params)
    };

    // ã‚¸ãƒ£ãƒ³ãƒ«ãƒ»ãƒ ãƒ¼ãƒ‰ã«åŸºã¥ã„ãŸã‚³ãƒ¼ãƒ‰é•·ã‚’è¨ˆç®—
    const genreChar = this.getGenreCharacteristics(params.genre);
    const moodChar = this.getMoodCharacteristics(params.mood);
    const baseChordDuration = (60 / (params.adjustedTempo || params.tempo)) * 4; // 4æ‹ã§1ã‚³ãƒ¼ãƒ‰
    const chordDuration = baseChordDuration * (genreChar.rhythmComplexity > 0.8 ? 0.5 : 1.0);
    const totalChords = Math.ceil(params.duration / chordDuration);

    console.log(`ğŸº Generating ${params.genre}/${params.mood} harmony: ${totalChords} chords, each ${chordDuration.toFixed(2)}s`);
    console.log(`ğŸµ Progression: ${harmony.progression.join(' - ')}, Instrument: ${harmony.instrument}`);

    for (let i = 0; i < totalChords; i++) {
      const chordSymbol = harmony.progression[i % harmony.progression.length];
      const chordNotes = this.chordToNotes(chordSymbol, params.key, params.genre);
      const chordFrequencies = this.calculateChordFrequencies(chordNotes, params, moodChar);
      
      // ç¢ºå®Ÿã«3éŸ³ä»¥ä¸Šã®ã‚³ãƒ¼ãƒ‰ã«ã™ã‚‹
      if (chordFrequencies.length < 3) {
        // ä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–ä¸Šã®éŸ³ã‚’è¿½åŠ 
        const baseFreq = chordFrequencies[0];
        for (let j = chordFrequencies.length; j < 3; j++) {
          chordFrequencies.push(baseFreq * Math.pow(2, j - chordFrequencies.length + 1));
        }
      }
      
      // éŸ³æ¥½çš„ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã‚³ãƒ¼ãƒ‰ã‚’é…ç½®
      const startTime = i * chordDuration;
      
      harmony.chords.push({
        symbol: chordSymbol,
        startTime: startTime,
        duration: chordDuration,
        notes: chordNotes,
        frequencies: chordFrequencies,
        voicing: this.selectChordVoicing(chordSymbol, params.genre),
        dynamics: this.calculateChordDynamics(i, totalChords, params, moodChar),
        genre: params.genre,
        mood: params.mood
      });
      
      console.log(`ğŸ¼ Chord ${i + 1}: ${chordSymbol} (${chordFrequencies.length} notes) @${startTime.toFixed(2)}s`);
    }

    console.log(`âœ… Generated ${harmony.chords.length} rich harmony chords for ${params.genre}/${params.mood}`);
    return harmony;
  }

  async synthesizeWithAdvancedEngine(melody, harmony, params) {
    console.log('ğŸ›ï¸ Starting advanced synthesis...');
    
    // äº‹å‰ã«ã™ã¹ã¦ã®éŸ³ç¬¦ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
    this.scheduledNotes = [];
    
    // ãƒ¡ãƒ­ãƒ‡ã‚£ãƒãƒ¼ãƒˆã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
    if (melody && melody.notes && melody.notes.length > 0) {
      console.log(`ğŸ¹ Scheduling ${melody.notes.length} melody notes...`);
      melody.notes.forEach(note => {
        this.scheduledNotes.push({
          type: 'melody',
          instrument: melody.instrument,
          frequency: note.frequency,
          startTime: note.startTime,
          duration: note.duration,
          velocity: note.velocity * 0.9, // ãƒ¡ãƒ­ãƒ‡ã‚£ã‚’æ˜ç­ã«
          noteInfo: `${note.note}${note.octave}`,
          genre: note.genre || params.genre,
          mood: note.mood || params.mood
        });
      });
    }
    
    // ãƒãƒ¼ãƒ¢ãƒ‹ãƒ¼ãƒãƒ¼ãƒˆã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆã‚¢ãƒ«ãƒšã‚¸ã‚ªã‚’å‰Šé™¤ã—ã¦ãƒ–ãƒ­ãƒƒã‚¯ã‚³ãƒ¼ãƒ‰ã«ï¼‰
    if (harmony && harmony.chords && harmony.chords.length > 0) {
      console.log(`ğŸº Scheduling ${harmony.chords.length} harmony chords...`);
      harmony.chords.forEach(chord => {
        // åŒæ™‚ã«ã‚³ãƒ¼ãƒ‰éŸ³ã‚’é³´ã‚‰ã™ï¼ˆã‚¢ãƒ«ãƒšã‚¸ã‚ªãªã—ï¼‰
        chord.frequencies.forEach((frequency, index) => {
          this.scheduledNotes.push({
            type: 'harmony',
            instrument: harmony.instrument,
            frequency: frequency,
            startTime: chord.startTime,
            duration: chord.duration,
            velocity: chord.dynamics * 0.8, // ãƒãƒ¼ãƒ¢ãƒ‹ãƒ¼ã‚’ã•ã‚‰ã«æ˜ç­ã«
            chordInfo: `${chord.symbol}[${index}]`,
            genre: params.genre,
            mood: params.mood
          });
        });
      });
    }
    
    // ãƒ‰ãƒ©ãƒ ãƒˆãƒ©ãƒƒã‚¯ã¯ä¸€æ—¦ç„¡åŠ¹åŒ–ï¼ˆéŸ³æ¥½çš„ã§ãªã„ãŸã‚ï¼‰
    // if (params.instruments.includes('drums')) {
    //   console.log('ğŸ¥ Scheduling drum track...');
    //   this.scheduleAdvancedDrums(params);
    // }
    
    // éŸ³ç¬¦ã‚’æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
    this.scheduledNotes.sort((a, b) => a.startTime - b.startTime);
    
    console.log(`ğŸ“… Total scheduled notes: ${this.scheduledNotes.length}`);
    console.log(`ğŸ“… First 5 notes:`, this.scheduledNotes.slice(0, 5).map(n => 
      `${n.type}:${n.noteInfo || n.chordInfo} @${n.startTime.toFixed(2)}s`
    ));
    
    // é«˜å“è³ªéŸ³éŸ¿åˆæˆã®å®Ÿè¡Œï¼ˆãƒãƒƒãƒ•ã‚¡ãƒ¼ç”Ÿæˆï¼‰
    return await this.renderToBuffer(params.duration);
  }

  async renderToBuffer(duration) {
    console.log('ğŸšï¸ Rendering to high-quality buffer...');
    
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆæˆã§ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    const sampleRate = this.audioContext.sampleRate;
    const samples = Math.floor(sampleRate * duration);
    const audioData = new Float32Array(samples);
    
    console.log(`ğŸ¼ Rendering ${this.scheduledNotes.length} notes over ${duration} seconds (${samples} samples)...`);
    
    // ã‚¹ã‚¿ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²ããŸã‚ã€ãƒãƒƒãƒå‡¦ç†ã§éŸ³ç¬¦ã‚’å‡¦ç†
    const batchSize = 10; // ä¸€åº¦ã«å‡¦ç†ã™ã‚‹éŸ³ç¬¦æ•°
    let processedNotes = 0;
    
    for (let batchStart = 0; batchStart < this.scheduledNotes.length; batchStart += batchSize) {
      const batchEnd = Math.min(batchStart + batchSize, this.scheduledNotes.length);
      const noteBatch = this.scheduledNotes.slice(batchStart, batchEnd);
      
      // ãƒãƒƒãƒå†…ã®å„éŸ³ç¬¦ã‚’å‡¦ç†
      for (const note of noteBatch) {
        const noteStartSample = Math.floor(note.startTime * sampleRate);
        const noteDurationSamples = Math.floor(note.duration * sampleRate);
        const noteEndSample = Math.min(samples, noteStartSample + noteDurationSamples);
        
        // å„éŸ³ç¬¦ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’åŠ¹ç‡çš„ã«ç”Ÿæˆ
        this.renderNoteToBuffer(note, audioData, noteStartSample, noteEndSample, sampleRate);
        processedNotes++;
      }
      
      // éåŒæœŸå‡¦ç†ã‚’æŒŸã‚“ã§ã‚¹ã‚¿ãƒƒã‚¯ã‚’ã‚¯ãƒªã‚¢
      if (batchStart % 50 === 0) { // 50éŸ³ç¬¦ã”ã¨ã«yield
        await new Promise(resolve => setTimeout(resolve, 0));
        console.log(`ğŸµ Processed ${processedNotes}/${this.scheduledNotes.length} notes...`);
      }
    }
    
    // ãƒã‚¹ã‚¿ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ èª¿æ•´ã¨ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢ï¼ˆæ”¹å–„ç‰ˆï¼‰
    let maxAmplitude = 0;
    for (let i = 0; i < samples; i++) {
      maxAmplitude = Math.max(maxAmplitude, Math.abs(audioData[i]));
    }
    
    // ã‚ˆã‚Šè‰¯ã„æ­£è¦åŒ–ï¼šãƒ˜ãƒƒãƒ‰ãƒ«ãƒ¼ãƒ ã‚’ç¢ºä¿ã—ã¤ã¤éŸ³é‡ã‚’æœ€å¤§åŒ–
    const targetLevel = 0.85; // ã‚ˆã‚Šé«˜ã„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¬ãƒ™ãƒ«
    const normalizationFactor = maxAmplitude > 0.1 ? targetLevel / maxAmplitude : 1.0;
    
    for (let i = 0; i < samples; i++) {
      audioData[i] *= normalizationFactor;
    }
    
    console.log(`âœ… High-quality rendering complete (original max: ${maxAmplitude.toFixed(3)}, normalized: ${targetLevel})`);
    return audioData;
  }

  // å€‹åˆ¥éŸ³ç¬¦ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼ˆã‚¹ã‚¿ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–ï¼‰
  renderNoteToBuffer(note, audioData, noteStartSample, noteEndSample, sampleRate) {
    for (let i = noteStartSample; i < noteEndSample; i++) {
      if (i >= 0 && i < audioData.length) {
        const noteTime = (i - noteStartSample) / sampleRate;
        const normalizedTime = noteTime / note.duration;
        
        // æ¥½å™¨åˆ¥ã®éŸ³è‰²åˆæˆï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ»ãƒ ãƒ¼ãƒ‰å¯¾å¿œï¼‰
        let noteSample = 0;
        
        if (note.instrument === 'piano') {
          noteSample = this.synthesizePiano(note.frequency, noteTime, note.velocity, note.genre, note.mood);
        } else if (note.instrument === 'guitar') {
          noteSample = this.synthesizeGuitar(note.frequency, noteTime, note.velocity, note.genre, note.mood);
        } else if (note.instrument === 'strings') {
          noteSample = this.synthesizeStrings(note.frequency, noteTime, note.velocity, note.genre, note.mood);
        } else if (note.instrument === 'synthesizer') {
          noteSample = this.synthesizeSynth(note.frequency, noteTime, note.velocity, note.genre, note.mood);
        } else if (note.instrument === 'bass') {
          noteSample = this.synthesizeBass(note.frequency, noteTime, note.velocity, note.genre, note.mood);
        } else {
          // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆæˆ
          noteSample = this.synthesizeDefault(note.frequency, noteTime, note.velocity);
        }
        
        // ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—é©ç”¨
        const envelope = this.calculateEnvelope(normalizedTime, note.instrument);
        const finalSample = noteSample * envelope;
        
        // ã‚µãƒ³ãƒ—ãƒ«ã‚’åŠ ç®—ï¼ˆè¤‡æ•°ã®éŸ³ç¬¦ãŒé‡ãªã‚‹å ´åˆï¼‰
        audioData[i] += finalSample;
      }
    }
  }

  // æ¥½å™¨åˆ¥åˆæˆãƒ¡ã‚½ãƒƒãƒ‰ç¾¤ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ»ãƒ ãƒ¼ãƒ‰å¯¾å¿œç‰ˆï¼‰
  synthesizePiano(frequency, time, velocity, genre = 'classical', mood = 'calm') {
    // ãƒ”ã‚¢ãƒã®å€éŸ³æ§‹é€ ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆå¼·åŒ–ç‰ˆï¼‰
    let sample = 0;
    
    // ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã®å€éŸ³ç‰¹æ€§ï¼ˆã‚ˆã‚Šæ˜ç­ã«ï¼‰
    let harmonics;
    if (genre === 'jazz') {
      harmonics = [1, 0.8, 0.5, 0.3, 0.2, 0.1]; // ã‚¸ãƒ£ã‚ºãƒ”ã‚¢ãƒï¼ˆå¼·åŒ–ï¼‰
    } else if (genre === 'rock') {
      harmonics = [1, 0.9, 0.6, 0.4, 0.2]; // ãƒ­ãƒƒã‚¯ãƒ”ã‚¢ãƒï¼ˆã‚ˆã‚Šæ˜ç­ï¼‰
    } else if (genre === 'electronic') {
      harmonics = [1, 0.9, 0.7, 0.5, 0.3, 0.2]; // é›»å­çš„ã§é‹­ã„ï¼ˆå¼·åŒ–ï¼‰
    } else {
      harmonics = [1, 0.7, 0.4, 0.25, 0.15, 0.1]; // ã‚¯ãƒ©ã‚·ãƒƒã‚¯æ¨™æº–ï¼ˆå¼·åŒ–ï¼‰
    }
    
    for (let i = 0; i < harmonics.length; i++) {
      const harmonicFreq = frequency * (i + 1);
      const amplitude = harmonics[i] * velocity * 1.2; // å…¨ä½“çš„ã«éŸ³é‡ã‚¢ãƒƒãƒ—
      sample += Math.sin(2 * Math.PI * harmonicFreq * time) * amplitude;
    }
    
    // ãƒ ãƒ¼ãƒ‰åˆ¥ã®æ¸›è¡°ç‰¹æ€§ï¼ˆã‚ˆã‚ŠæŒç¶šçš„ã«ï¼‰
    let decayRate = 1.5; // ã‚ˆã‚ŠæŒç¶šçš„
    if (mood === 'dramatic') decayRate = 1.0; // ã‚ˆã‚ŠæŒç¶šçš„
    if (mood === 'energetic') decayRate = 2.0; // ã‚„ã‚„çŸ­ãã€ãƒ‘ãƒ³ãƒã®ã‚ã‚‹éŸ³
    if (mood === 'peaceful') decayRate = 0.8; // ã‚†ã£ãã‚Šã¨ã—ãŸæ¸›è¡°
    
    const decay = Math.exp(-time * decayRate);
    return sample * decay;
  }

  synthesizeGuitar(frequency, time, velocity, genre = 'rock', mood = 'energetic') {
    // ã‚®ã‚¿ãƒ¼ã®å¼¦ã®æŒ¯å‹•ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    let sample = 0;
    
    // ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã®éŸ³è‰²ç‰¹æ€§
    let harmonics, noiseLevel;
    if (genre === 'classical') {
      harmonics = [1, 0.6, 0.4, 0.3, 0.2, 0.1];
      noiseLevel = 0.01; // ã‚¯ãƒªãƒ¼ãƒ³ãªéŸ³
    } else if (genre === 'rock') {
      harmonics = [1, 0.8, 0.6, 0.4, 0.3, 0.2];
      noiseLevel = 0.05; // ãƒ‡ã‚£ã‚¹ãƒˆãƒ¼ã‚·ãƒ§ãƒ³åŠ¹æœ
    } else if (genre === 'jazz') {
      harmonics = [1, 0.7, 0.5, 0.3, 0.2, 0.15];
      noiseLevel = 0.02; // æ¸©ã‹ã„éŸ³è‰²
    } else {
      harmonics = [1, 0.8, 0.6, 0.4, 0.3, 0.2];
      noiseLevel = 0.03;
    }
    
    for (let i = 0; i < harmonics.length; i++) {
      const harmonicFreq = frequency * (i + 1);
      const amplitude = harmonics[i] * velocity;
      sample += Math.sin(2 * Math.PI * harmonicFreq * time) * amplitude;
      
      // ãƒ ãƒ¼ãƒ‰åˆ¥ãƒã‚¤ã‚ºèª¿æ•´
      const moodNoiseMultiplier = mood === 'energetic' ? 2 : mood === 'calm' ? 0.5 : 1;
      sample += (Math.random() - 0.5) * noiseLevel * amplitude * moodNoiseMultiplier;
    }
    
    const decay = Math.exp(-time * 1.5);
    return sample * decay;
  }

  synthesizeStrings(frequency, time, velocity, genre = 'classical', mood = 'dramatic') {
    // ã‚¹ãƒˆãƒªãƒ³ã‚°ã‚¹ã®è±Šã‹ãªå€éŸ³
    let sample = 0;
    
    // ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã®å€éŸ³æ§‹æˆï¼ˆã‚ˆã‚Šæ˜ç­ã«ï¼‰
    let harmonics;
    if (genre === 'cinematic') {
      harmonics = [1, 0.9, 0.7, 0.6, 0.5, 0.4, 0.3, 0.25]; // æ˜ ç”»çš„ãªè±Šã‹ã•
    } else if (genre === 'ambient') {
      harmonics = [1, 0.8, 0.5, 0.4, 0.3, 0.2, 0.15]; // å¤§æ°—çš„ã ãŒã‚ˆã‚Šæ˜ç­
    } else {
      harmonics = [1, 0.85, 0.6, 0.5, 0.4, 0.3, 0.25, 0.2]; // ã‚¯ãƒ©ã‚·ãƒƒã‚¯æ¨™æº–ï¼ˆå¼·åŒ–ï¼‰
    }
    
    for (let i = 0; i < harmonics.length; i++) {
      const harmonicFreq = frequency * (i + 1);
      const amplitude = harmonics[i] * velocity;
      
      // ãƒ ãƒ¼ãƒ‰åˆ¥ã®ä½ç›¸å¤‰èª¿
      let phaseModulation = 0;
      if (mood === 'dramatic') {
        phaseModulation = Math.sin(2 * Math.PI * 3 * time) * 0.1; // ãƒ“ãƒ–ãƒ©ãƒ¼ãƒˆåŠ¹æœ
      }
      
      sample += Math.sin(2 * Math.PI * harmonicFreq * time + phaseModulation) * amplitude;
    }
    
    // ãƒ ãƒ¼ãƒ‰åˆ¥ã®æŒç¶šç‰¹æ€§ï¼ˆã‚ˆã‚ŠæŒç¶šçš„ã«ï¼‰
    let decayRate = 0.6; // ã‚ˆã‚Šé•·ã„æŒç¶š
    if (mood === 'peaceful') decayRate = 0.4; // ã•ã‚‰ã«é•·ã„æŒç¶š
    if (mood === 'energetic') decayRate = 1.0; // ã‚„ã‚„çŸ­ã„æŒç¶š
    
    const decay = Math.exp(-time * decayRate);
    return sample * decay;
  }

  synthesizeSynth(frequency, time, velocity, genre = 'electronic', mood = 'energetic') {
    // ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼ã®ãƒªãƒƒãƒãªéŸ³è‰²ï¼ˆæ”¹å–„ç‰ˆï¼‰
    let sample = 0;
    
    // ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã®æ³¢å½¢é¸æŠï¼ˆéŸ³é‡å¼·åŒ–ï¼‰
    if (genre === 'electronic') {
      // è¤‡æ•°ã‚ªã‚·ãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ãƒ‡ãƒãƒ¥ãƒ¼ãƒ³ï¼ˆå¼·åŒ–ï¼‰
      sample += Math.sin(2 * Math.PI * frequency * time) * 0.8; // ãƒ¡ã‚¤ãƒ³éŸ³é‡ã‚¢ãƒƒãƒ—
      sample += Math.sin(2 * Math.PI * frequency * 1.01 * time) * 0.4; // ãƒ‡ãƒãƒ¥ãƒ¼ãƒ³å¼·åŒ–
      sample += Math.sin(2 * Math.PI * frequency * 2 * time) * 0.4; // å€éŸ³å¼·åŒ–
      sample += this.generateSquareWave(frequency, time) * 0.3; // çŸ©å½¢æ³¢å¼·åŒ–
    } else if (genre === 'ambient') {
      // ãƒ‘ãƒƒãƒ‰ç³»ã®éŸ³è‰²ï¼ˆå¼·åŒ–ï¼‰
      sample += Math.sin(2 * Math.PI * frequency * time) * 0.9; // ãƒ¡ã‚¤ãƒ³å¼·åŒ–
      sample += Math.sin(2 * Math.PI * frequency * 0.5 * time) * 0.4; // ã‚µãƒ–ã‚ªã‚·ãƒ¬ãƒ¼ã‚¿ãƒ¼å¼·åŒ–
      sample += Math.sin(2 * Math.PI * frequency * 3 * time) * 0.2; // å€éŸ³è¿½åŠ 
    } else {
      // æ¨™æº–ã‚·ãƒ³ã‚»ï¼ˆå¼·åŒ–ï¼‰
      sample += Math.sin(2 * Math.PI * frequency * time) * 0.8; // ãƒ¡ã‚¤ãƒ³å¼·åŒ–
      sample += Math.sin(2 * Math.PI * frequency * 2 * time) * 0.4; // å€éŸ³å¼·åŒ–
      sample += Math.sin(2 * Math.PI * frequency * 3 * time) * 0.2; // é«˜æ¬¡å€éŸ³å¼·åŒ–
    }
    
    // ãƒ ãƒ¼ãƒ‰åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åŠ¹æœï¼ˆã‚ˆã‚Šæ˜ç­ã«ï¼‰
    let filterEffect = 1;
    if (mood === 'dramatic') {
      filterEffect = 0.7 + 0.3 * Math.sin(2 * Math.PI * 2 * time); // ã‚ªãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆæ”¹è‰¯ï¼‰
    } else if (mood === 'calm') {
      filterEffect = 0.8; // ãƒ­ãƒ¼ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åŠ¹æœï¼ˆæ”¹è‰¯ï¼‰
    }
    
    sample *= filterEffect;
    
    const decay = Math.exp(-time * 1.0); // ã‚ˆã‚ŠæŒç¶šçš„
    return sample * decay * velocity * 1.3; // å…¨ä½“éŸ³é‡ã‚¢ãƒƒãƒ—
  }

  synthesizeBass(frequency, time, velocity, genre = 'rock', mood = 'energetic') {
    // ãƒ™ãƒ¼ã‚¹ã®ä½éŸ³å¼·åŒ–
    let sample = 0;
    
    // ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã®ä½éŸ³ç‰¹æ€§
    if (genre === 'jazz') {
      // ã‚¢ãƒƒãƒ—ãƒ©ã‚¤ãƒˆãƒ™ãƒ¼ã‚¹é¢¨
      sample += Math.sin(2 * Math.PI * frequency * time) * 0.8;
      sample += Math.sin(2 * Math.PI * frequency * 2 * time) * 0.2;
      sample += (Math.random() - 0.5) * 0.05; // ãƒ•ã‚£ãƒ³ã‚¬ãƒ¼ãƒã‚¤ã‚º
    } else if (genre === 'electronic') {
      // é›»å­ãƒ™ãƒ¼ã‚¹
      sample += Math.sin(2 * Math.PI * frequency * time) * 0.9;
      sample += this.generateSquareWave(frequency * 0.5, time) * 0.4; // ã‚µãƒ–ãƒ™ãƒ¼ã‚¹
      sample += Math.sin(2 * Math.PI * frequency * 3 * time) * 0.1;
    } else {
      // ã‚¨ãƒ¬ã‚­ãƒ™ãƒ¼ã‚¹
      sample += Math.sin(2 * Math.PI * frequency * time) * 0.8;
      sample += Math.sin(2 * Math.PI * frequency * 2 * time) * 0.2;
      sample += Math.sin(2 * Math.PI * frequency * 0.5 * time) * 0.3; // ã‚µãƒ–ãƒ™ãƒ¼ã‚¹
    }
    
    // ãƒ ãƒ¼ãƒ‰åˆ¥ã‚¢ã‚¿ãƒƒã‚¯èª¿æ•´
    let attackEnvelope = 1;
    if (mood === 'energetic') {
      attackEnvelope = Math.min(1, time * 50); // ã‚·ãƒ£ãƒ¼ãƒ—ãªã‚¢ã‚¿ãƒƒã‚¯
    } else if (mood === 'calm') {
      attackEnvelope = Math.min(1, time * 10); // ã‚½ãƒ•ãƒˆãªã‚¢ã‚¿ãƒƒã‚¯
    }
    
    const decay = Math.exp(-time * 1.0);
    return sample * decay * velocity * attackEnvelope;
  }

  // çŸ©å½¢æ³¢ç”Ÿæˆãƒ˜ãƒ«ãƒ‘ãƒ¼
  generateSquareWave(frequency, time) {
    return Math.sign(Math.sin(2 * Math.PI * frequency * time));
  }

  synthesizeDrum(drumType, time, velocity) {
    let sample = 0;
    
    if (drumType === 'kick') {
      // ã‚­ãƒƒã‚¯ãƒ‰ãƒ©ãƒ ï¼šä½éŸ³ãƒã‚¤ã‚º + çŸ­ã„ãƒˆãƒ¼ãƒ³
      const tone = Math.sin(2 * Math.PI * 60 * time);
      const noise = (Math.random() - 0.5) * 0.5;
      const env = Math.exp(-time * 20);
      sample = (tone * 0.8 + noise * 0.2) * env;
    } else if (drumType === 'snare') {
      // ã‚¹ãƒã‚¢ãƒ‰ãƒ©ãƒ ï¼šãƒã‚¤ã‚º + 200Hzã®ãƒˆãƒ¼ãƒ³
      const tone = Math.sin(2 * Math.PI * 200 * time);
      const noise = (Math.random() - 0.5);
      const env = Math.exp(-time * 15);
      sample = (tone * 0.3 + noise * 0.7) * env;
    } else if (drumType === 'hihat') {
      // ãƒã‚¤ãƒãƒƒãƒˆï¼šé«˜å‘¨æ³¢ãƒã‚¤ã‚º
      const noise = (Math.random() - 0.5);
      const filter = Math.sin(2 * Math.PI * 8000 * time);
      const env = Math.exp(-time * 30);
      sample = noise * filter * env * 0.3;
    }
    
    return sample * velocity;
  }

  synthesizeDefault(frequency, time, velocity) {
    // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆæˆï¼ˆåŸºæœ¬çš„ãªæ­£å¼¦æ³¢ï¼‰
    const sample = Math.sin(2 * Math.PI * frequency * time);
    const decay = Math.exp(-time * 1.5);
    return sample * decay * velocity;
  }

  calculateEnvelope(normalizedTime, instrument) {
    // ADSR ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—
    const instrumentEnvelopes = {
      'piano': { attack: 0.01, decay: 0.3, sustain: 0.7, release: 0.7 },
      'guitar': { attack: 0.02, decay: 0.2, sustain: 0.8, release: 0.8 },
      'strings': { attack: 0.1, decay: 0.1, sustain: 0.9, release: 0.9 },
      'synthesizer': { attack: 0.05, decay: 0.2, sustain: 0.7, release: 0.3 },
      'bass': { attack: 0.01, decay: 0.1, sustain: 0.9, release: 0.5 }
    };
    
    const envelope = instrumentEnvelopes[instrument] || instrumentEnvelopes['piano'];
    
    if (normalizedTime < envelope.attack) {
      // ã‚¢ã‚¿ãƒƒã‚¯æ®µéš
      return normalizedTime / envelope.attack;
    } else if (normalizedTime < envelope.attack + envelope.decay) {
      // ãƒ‡ã‚£ã‚±ã‚¤æ®µéš
      const decayTime = (normalizedTime - envelope.attack) / envelope.decay;
      return 1 - (1 - envelope.sustain) * decayTime;
    } else if (normalizedTime < 1 - envelope.release) {
      // ã‚µã‚¹ãƒ†ã‚¤ãƒ³æ®µéš
      return envelope.sustain;
    } else {
      // ãƒªãƒªãƒ¼ã‚¹æ®µéš
      const releaseTime = (normalizedTime - (1 - envelope.release)) / envelope.release;
      return envelope.sustain * (1 - releaseTime);
    }
  }

  // é«˜åº¦ãªæ¥½å™¨é¸æŠã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—
  calculateMusicParameters(settings) {
    console.log('Calculating music parameters from settings:', settings);
    
    const params = {
      tempo: this.getTempoValue(settings.tempo),
      duration: this.getDurationValue(settings.duration),
      key: this.getKeyFromMood(settings.mood),
      scale: this.getScaleFromGenre(settings.genre),
      complexity: settings.complexity || 'moderate',
      instruments: settings.instruments || ['piano', 'strings'],
      loop: settings.loop || false,
      mood: settings.mood || 'calm',
      genre: settings.genre || 'ambient',
      volume: settings.volume || 0.7,
      harmony: settings.harmony || 'consonant',
      dynamics: settings.dynamics || 'balanced'
    };
    
    // ãƒ ãƒ¼ãƒ‰ã¨ã‚¸ãƒ£ãƒ³ãƒ«ã®ç‰¹æ€§ã‚’è€ƒæ…®ã—ãŸãƒ†ãƒ³ãƒèª¿æ•´
    const moodCharacteristics = this.getMoodCharacteristics(params.mood);
    params.adjustedTempo = Math.round(params.tempo * moodCharacteristics.tempoModifier);
    
    console.log('Music parameters calculated:', params);
    return params;
  }

  selectMelodyInstrument(instruments) {
    console.log('Selecting melody instrument from:', instruments);
    
    // ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’è¿½åŠ ã—ã¦åŒã˜æ¥½å™¨é…åˆ—ã§ã‚‚ç•°ãªã‚‹æ¥½å™¨ã‚’é¸æŠ
    const shuffledInstruments = [...instruments].sort(() => Math.random() - 0.5);
    
    const melodyPriority = ['piano', 'guitar', 'synthesizer', 'strings', 'electronic'];
    
    // 30%ã®ç¢ºç‡ã§å®Œå…¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    if (Math.random() < 0.3 && shuffledInstruments.length > 0) {
      const randomChoice = shuffledInstruments[Math.floor(Math.random() * shuffledInstruments.length)];
      console.log('Random melody instrument selected:', randomChoice);
      return randomChoice;
    }
    
    // å„ªå…ˆé †ä½ã‹ã‚‰é¸æŠï¼ˆãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ä»˜ãï¼‰
    const availablePriority = melodyPriority.filter(inst => instruments.includes(inst));
    if (availablePriority.length > 0) {
      // ä¸Šä½2ã¤ã‹ã‚‰ç¢ºç‡çš„ã«é¸æŠ
      const topChoices = availablePriority.slice(0, Math.min(2, availablePriority.length));
      const selected = topChoices[Math.floor(Math.random() * topChoices.length)];
      console.log('Priority-based melody instrument selected:', selected);
      return selected;
    }
    
    const selected = shuffledInstruments[0] || 'piano';
    console.log('Default melody instrument:', selected);
    return selected;
  }

  selectHarmonyInstrument(instruments) {
    console.log('Selecting harmony instrument from:', instruments);
    
    // ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’è¿½åŠ 
    const shuffledInstruments = [...instruments].sort(() => Math.random() - 0.5);
    
    // ãƒãƒ¼ãƒ¢ãƒ‹ãƒ¼ã«ã¯ç•°ãªã‚‹æ¥½å™¨ã‚’é¸ã¶å„ªå…ˆé †ä½
    const harmonyPriority = ['strings', 'synthesizer', 'piano', 'guitar'];
    
    // 40%ã®ç¢ºç‡ã§å®Œå…¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    if (Math.random() < 0.4 && shuffledInstruments.length > 0) {
      const randomChoice = shuffledInstruments[Math.floor(Math.random() * shuffledInstruments.length)];
      console.log('Random harmony instrument selected:', randomChoice);
      return randomChoice;
    }
    
    // å„ªå…ˆé †ä½ã‹ã‚‰é¸æŠï¼ˆãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ä»˜ãï¼‰
    const availablePriority = harmonyPriority.filter(inst => instruments.includes(inst));
    if (availablePriority.length > 0) {
      // ä¸Šä½3ã¤ã‹ã‚‰ç¢ºç‡çš„ã«é¸æŠ
      const topChoices = availablePriority.slice(0, Math.min(3, availablePriority.length));
      const selected = topChoices[Math.floor(Math.random() * topChoices.length)];
      console.log('Priority-based harmony instrument selected:', selected);
      return selected;
    }
    
    const selected = shuffledInstruments[0] || 'strings';
    console.log('Default harmony instrument:', selected);
    return selected;
  }

  selectMelodicOctave(note, genre, phraseIndex, mood = 'calm') {
    const baseOctave = 4;
    
    // ã‚¸ãƒ£ãƒ³ãƒ«ã«ã‚ˆã‚‹åŸºæœ¬ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–èª¿æ•´
    const genreOctaveMap = {
      'classical': 4,
      'jazz': 4,
      'rock': 4,
      'electronic': 5,
      'ambient': 4,
      'cinematic': 4
    };
    
    // ãƒ ãƒ¼ãƒ‰ã«ã‚ˆã‚‹èª¿æ•´
    const moodOctaveShift = {
      'calm': 0,
      'energetic': 1,
      'dramatic': 0,
      'peaceful': -1,
      'uplifting': 1,
      'melancholic': -1
    };
    
    const genreOctave = genreOctaveMap[genre] || baseOctave;
    const moodShift = moodOctaveShift[mood] || 0;
    
    return genreOctave + moodShift;
  }

  selectAdvancedProgression(params) {
    // è¤‡æ•°ã®ã‚³ãƒ¼ãƒ‰é€²è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”¨æ„ã—ã€ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    const allProgressions = {
      'classical': [
        ['I', 'vi', 'IV', 'V'],   // Canon progression
        ['I', 'V', 'vi', 'IV'],   // Popular progression  
        ['I', 'IV', 'V', 'I'],    // Simple classical
        ['vi', 'IV', 'I', 'V'],   // vi-IV-I-V
        ['I', 'ii', 'V', 'I']     // ii-V-I classical
      ],
      'jazz': [
        ['I', 'vi', 'ii', 'V'],   // ii-V-I progression
        ['I', 'VI', 'ii', 'V'],   // Extended ii-V-I
        ['I', 'iii', 'vi', 'ii'], // Circle of fifths
        ['vi', 'ii', 'V', 'I'],   // Reverse ii-V-I
        ['I', 'IV', 'vii', 'iii'] // Jazz alternative
      ],
      'rock': [
        ['I', 'V', 'vi', 'IV'],   // Popular progression
        ['vi', 'IV', 'I', 'V'],   // vi-IV-I-V
        ['I', 'bVII', 'IV', 'I'], // Rock power chords
        ['i', 'VI', 'VII', 'i'],  // Minor rock
        ['I', 'iii', 'IV', 'V']   // Ascending rock
      ],
      'electronic': [
        ['vi', 'IV', 'I', 'V'],   // vi-IV-I-V
        ['I', 'V', 'vi', 'IV'],   // Popular progression
        ['vi', 'ii', 'IV', 'V'],  // Electronic variant
        ['I', 'bVII', 'vi', 'V'], // Electronic minor
        ['vi', 'V', 'IV', 'iii']  // Descending electronic
      ],
      'ambient': [
        ['I', 'V', 'vi', 'IV'],   // Calm progression
        ['vi', 'IV', 'I', 'V'],   // Peaceful flow
        ['I', 'iii', 'vi', 'IV'], // Soft ambient
        ['vi', 'ii', 'V', 'I'],   // Dreamy ambient
        ['I', 'IV', 'vi', 'V']    // Floating ambient
      ],
      'cinematic': [
        ['i', 'VI', 'iv', 'V'],   // Dramatic minor
        ['i', 'VII', 'VI', 'VII'], // Epic cinematic
        ['i', 'v', 'VI', 'iv'],   // Dark cinematic
        ['VI', 'VII', 'i', 'v'],  // Rising tension
        ['i', 'III', 'VI', 'iv']  // Orchestral minor
      ]
    };

    const genreProgressions = allProgressions[params.genre] || allProgressions['ambient'];
    
    // ãƒ©ãƒ³ãƒ€ãƒ ã«é€²è¡Œã‚’é¸æŠ
    const selectedProgression = genreProgressions[Math.floor(Math.random() * genreProgressions.length)];
    
    console.log(`ğŸ¼ Selected progression for ${params.genre}: ${selectedProgression.join(' - ')}`);
    return selectedProgression;
  }

  chordToNotes(chordSymbol, key, genre) {
    const scaleNotes = this.getScaleNotes(key, this.getScaleFromGenre(genre));
    
    // ã‚³ãƒ¼ãƒ‰æ§‹æˆéŸ³ã®åŸºæœ¬ãƒ‘ã‚¿ãƒ¼ãƒ³
    const chordPatterns = {
      'I': [0, 2, 4],           // C E G
      'ii': [1, 3, 5],          // D F A
      'iii': [2, 4, 6],         // E G B
      'IV': [3, 5, 0],          // F A C
      'V': [4, 6, 1],           // G B D
      'vi': [5, 0, 2],          // A C E
      'vii': [6, 1, 3],         // B D F
      'i': [0, 2, 4],           // ãƒã‚¤ãƒŠãƒ¼ã‚­ãƒ¼ã§ã® i
      'VII': [6, 1, 3],         // ãƒ•ãƒ©ãƒƒãƒˆ7åº¦
      'VI': [5, 0, 2],          // ãƒ•ãƒ©ãƒƒãƒˆ6åº¦
      'IMaj7': [0, 2, 4, 6],    // ã‚¸ãƒ£ã‚ºã‚³ãƒ¼ãƒ‰
      'vi7': [5, 0, 2, 4],
      'ii7': [1, 3, 5, 0],
      'V7': [4, 6, 1, 3],
      'VIMaj7': [5, 0, 2, 4],
      'im7': [0, 2, 4, 6],
      'iv7': [3, 5, 0, 2],
      'VII7': [6, 1, 3, 5],
      'III7': [2, 4, 6, 1],
      'ii7b5': [1, 3, 5, 0]
    };
    
    const pattern = chordPatterns[chordSymbol] || chordPatterns['I'];
    return pattern.map(index => scaleNotes[index % scaleNotes.length]);
  }

  calculateChordDuration(params) {
    const baseDuration = 60 / params.tempo * 4; // 4æ‹åˆ†
    return baseDuration;
  }

  calculateChordFrequencies(chordNotes, params, moodChar = null) {
    let baseOctave = 3; // ãƒãƒ¼ãƒ¢ãƒ‹ãƒ¼ã¯ä½ã‚ã®ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–
    
    // ãƒ ãƒ¼ãƒ‰ã«åŸºã¥ãã‚ªã‚¯ã‚¿ãƒ¼ãƒ–èª¿æ•´
    if (moodChar && moodChar.octaveShift) {
      baseOctave += moodChar.octaveShift;
    }
    
    return chordNotes.map((note, index) => {
      const octave = baseOctave + Math.floor(index / 3);
      return this.noteToFrequency(note, octave);
    });
  }

  selectChordVoicing(chordSymbol, genre) {
    // ã‚¸ãƒ£ãƒ³ãƒ«ã«å¿œã˜ãŸãƒœã‚¤ã‚·ãƒ³ã‚°
    const voicings = {
      'jazz': 'extended', // 9th, 11th, 13thã‚’å«ã‚€
      'classical': 'close',
      'rock': 'open',
      'electronic': 'sparse',
      'ambient': 'wide',
      'cinematic': 'orchestral'
    };
    
    return voicings[genre] || 'close';
  }

  calculateChordDynamics(chordIndex, totalChords, params, moodChar = null) {
    const position = chordIndex / totalChords;
    
    // ãƒ ãƒ¼ãƒ‰ã«åŸºã¥ãåŸºæœ¬ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹
    let baseDynamics = 0.7;
    if (moodChar) {
      baseDynamics = moodChar.velocityBase;
    }
    
    // æ¥½æ›²æ§‹é€ ã«ã‚ˆã‚‹å‹•çš„å¤‰åŒ–
    if (position < 0.25) return baseDynamics * 0.8; // é™ã‹ãªå§‹ã¾ã‚Š
    if (position < 0.75) return baseDynamics * 1.1; // ç››ã‚Šä¸ŠãŒã‚Š
    return baseDynamics * 0.9; // é™ã‹ãªçµ‚ã‚ã‚Š
  }

  scheduleAdvancedDrums(params) {
    const beatDuration = 60 / params.tempo;
    const totalBeats = Math.floor(params.duration / beatDuration);
    
    for (let beat = 0; beat < totalBeats; beat++) {
      const beatTime = beat * beatDuration;
      
      // ã‚­ãƒƒã‚¯
      if (beat % 4 === 0) {
        this.scheduledNotes.push({
          type: 'drum',
          instrument: 'kick',
          frequency: 60,
          startTime: beatTime,
          duration: 0.1,
          velocity: 0.8
        });
      }
      
      // ã‚¹ãƒã‚¢
      if (beat % 4 === 2) {
        this.scheduledNotes.push({
          type: 'drum',
          instrument: 'snare',
          frequency: 200,
          startTime: beatTime,
          duration: 0.1,
          velocity: 0.7
        });
      }
      
      // ãƒã‚¤ãƒãƒƒãƒˆ
      if (params.genre === 'electronic' && beat % 2 === 1) {
        this.scheduledNotes.push({
          type: 'drum',
          instrument: 'hihat',
          frequency: 8000,
          startTime: beatTime,
          duration: 0.05,
          velocity: 0.4
        });
      }
    }
  }

  // é«˜å“è³ªå†ç”Ÿæ©Ÿèƒ½
  async playMusic() {
    if (!this.currentMusic || !this.currentMusic.audioData) {
      console.error('âŒ No music data available for playback');
      return false;
    }

    if (this.isPlaying) {
      console.log('â¸ï¸ Music already playing, stopping first...');
      this.stopMusic();
    }

    try {
      // AudioContextã®å†é–‹
      if (this.audioContext.state === 'suspended') {
        await this.audioContext.resume();
      }

      console.log('ğŸµ Starting high-quality playback...');
      
      // AudioBufferã‚’ä½œæˆ
      const audioBuffer = this.audioContext.createBuffer(
        1, // ãƒ¢ãƒãƒ©ãƒ«
        this.currentMusic.audioData.length,
        this.audioContext.sampleRate
      );
      
      const channelData = audioBuffer.getChannelData(0);
      channelData.set(this.currentMusic.audioData);
      
      // AudioBufferSourceNodeã‚’ä½œæˆ
      this.bufferSource = this.audioContext.createBufferSource();
      this.bufferSource.buffer = audioBuffer;
      
      // é«˜å“è³ªå†ç”Ÿãƒã‚§ãƒ¼ãƒ³ã«æ¥ç¶š
      this.bufferSource.connect(this.advancedEngine.masterGain);
      
      // å†ç”Ÿé–‹å§‹
      this.bufferSource.start(0);
      this.isPlaying = true;
      
      // å†ç”Ÿçµ‚äº†ã®ãƒªã‚¹ãƒŠãƒ¼
      this.bufferSource.onended = () => {
        this.isPlaying = false;
        console.log('ğŸµ Playback completed');
        this.notifyPlaybackState('stopped');
      };
      
      console.log('âœ… High-quality playback started');
      this.notifyPlaybackState('playing');
      return true;
      
    } catch (error) {
      console.error('âŒ High-quality playback failed:', error);
      this.isPlaying = false;
      this.notifyPlaybackState('error');
      return false;
    }
  }

  stopMusic() {
    if (this.bufferSource) {
      try {
        this.bufferSource.stop();
        this.bufferSource.disconnect();
        this.bufferSource = null;
      } catch (error) {
        console.warn('âš ï¸ Error stopping playback:', error);
      }
    }
    
    this.isPlaying = false;
    console.log('â¹ï¸ Playback stopped');
    this.notifyPlaybackState('stopped');
  }

  pauseMusic() {
    // Web Audio APIã«ã¯pauseãŒãªã„ãŸã‚ã€stopã‚’ä½¿ç”¨
    this.stopMusic();
  }

  // ã‚¤ãƒ™ãƒ³ãƒˆé€šçŸ¥
  notifyProgress(progress, message) {
    const event = new CustomEvent('musicGenerationProgress', {
      detail: { progress, message }
    });
    document.dispatchEvent(event);
  }

  notifyPlaybackState(state) {
    const event = new CustomEvent('musicPlaybackState', {
      detail: { state, isPlaying: this.isPlaying }
    });
    document.dispatchEvent(event);
  }

  // æ³¢å½¢ç”Ÿæˆ
  generateWaveform(audioData) {
    const waveformLength = 200;
    const step = Math.floor(audioData.length / waveformLength);
    const waveform = [];
    
    for (let i = 0; i < waveformLength; i++) {
      const sampleIndex = i * step;
      if (sampleIndex < audioData.length) {
        waveform.push(audioData[sampleIndex]);
      } else {
        waveform.push(0);
      }
    }
    
    return waveform;
  }

  // WAVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
  exportToWav() {
    if (!this.currentMusic || !this.currentMusic.audioData) {
      console.error('âŒ No music data available for export');
      return null;
    }

    console.log('ğŸ’¾ Exporting high-quality WAV...');
    
    const audioData = this.currentMusic.audioData;
    const sampleRate = this.audioContext.sampleRate;
    
    // WAVãƒ˜ãƒƒãƒ€ãƒ¼ç”Ÿæˆ
    const arrayBuffer = new ArrayBuffer(44 + audioData.length * 2);
    const view = new DataView(arrayBuffer);
    
    // WAVãƒ˜ãƒƒãƒ€ãƒ¼ã®æ›¸ãè¾¼ã¿
    const writeString = (offset, string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + audioData.length * 2, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, 1, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, audioData.length * 2, true);
    
    // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›ï¼ˆFloat32 â†’ Int16ï¼‰
    let offset = 44;
    for (let i = 0; i < audioData.length; i++) {
      const sample = Math.max(-1, Math.min(1, audioData[i]));
      view.setInt16(offset, sample * 0x7FFF, true);
      offset += 2;
    }
    
    console.log('âœ… High-quality WAV export complete');
    return arrayBuffer;
  }

  // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯éŸ³æ¥½ç”Ÿæˆ
  generateFallbackMusic(settings) {
    console.log('âš ï¸ Generating fallback music...');
    
    const duration = this.getDurationValue(settings.duration);
    const sampleRate = this.audioContext ? this.audioContext.sampleRate : 44100;
    const samples = Math.floor(sampleRate * duration);
    const audioData = new Float32Array(samples);
    
    // é«˜å“è³ªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯éŸ³ï¼ˆè¤‡æ•°å€éŸ³ï¼‰
    for (let i = 0; i < samples; i++) {
      const time = i / sampleRate;
      const envelope = Math.exp(-time * 0.8);
      
      let sample = 0;
      sample += Math.sin(2 * Math.PI * 440 * time) * 0.5;      // åŸºéŸ³
      sample += Math.sin(2 * Math.PI * 880 * time) * 0.25;     // 2å€éŸ³
      sample += Math.sin(2 * Math.PI * 1320 * time) * 0.125;   // 3å€éŸ³
      
      audioData[i] = sample * envelope * 0.3;
    }

    return {
      audioData: audioData,
      waveform: this.generateWaveform(audioData),
      melody: { notes: [], instrument: 'piano' },
      harmony: { chords: [] },
      params: { duration, tempo: 120, key: 'C' },
      metadata: {
        duration: duration,
        tempo: 120,
        key: 'C',
        genre: settings.genre || 'ambient',
        mood: settings.mood || 'calm',
        instruments: settings.instruments || ['piano'],
        generatedAt: new Date().toISOString(),
        engine: 'Fallback',
        quality: 'Basic'
      }
    };
  }

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  cleanup() {
    this.stopMusic();
    
    if (this.advancedEngine) {
      this.advancedEngine.cleanup();
    }
    
    if (this.audioContext) {
      this.audioContext.close();
    }
    
    this.scheduledNotes = [];
    this.activeNotes = [];
  }

  // è¤‡é›‘ã•ä¿‚æ•°ã®å–å¾—
  getComplexityFactor(complexity) {
    const factors = {
      'simple': {
        durationMultiplier: 1.2,    // ã‚ˆã‚Šé•·ã„éŸ³ç¬¦
        noteVariation: 0.3,         // å°‘ãªã„éŸ³ç¨‹å¤‰åŒ–
        rhythmComplexity: 0.5,      // ã‚·ãƒ³ãƒ—ãƒ«ãªãƒªã‚ºãƒ 
        restProbability: 0.1        // å°‘ãªã„ä¼‘ç¬¦
      },
      'moderate': {
        durationMultiplier: 1.0,    // æ¨™æº–ã®éŸ³ç¬¦é•·
        noteVariation: 0.6,         // é©åº¦ãªéŸ³ç¨‹å¤‰åŒ–
        rhythmComplexity: 0.7,      // æ¨™æº–çš„ãªãƒªã‚ºãƒ 
        restProbability: 0.15       // é©åº¦ãªä¼‘ç¬¦
      },
      'complex': {
        durationMultiplier: 0.8,    // ã‚ˆã‚ŠçŸ­ã„éŸ³ç¬¦
        noteVariation: 0.9,         // å¤šãã®éŸ³ç¨‹å¤‰åŒ–
        rhythmComplexity: 0.9,      // è¤‡é›‘ãªãƒªã‚ºãƒ 
        restProbability: 0.25       // å¤šãã®ä¼‘ç¬¦
      }
    };
    
    return factors[complexity] || factors['moderate'];
  }

  // ã‚¸ãƒ£ãƒ³ãƒ«ã¨ãƒ ãƒ¼ãƒ‰ã«åŸºã¥ããƒ¡ãƒ­ãƒ‡ã‚£ãƒãƒ¼ãƒˆé¸æŠï¼ˆæ›´æ–°ç‰ˆãƒ»ã‚ˆã‚Šå¤šæ§˜æ€§ï¼‰
  selectMelodyNote(measurePosition, currentScaleIndex, scaleLength, genreCharacteristics, moodCharacteristics, complexityFactor = null) {
    if (measurePosition === 0) {
      // å°ç¯€ã®æœ€åˆï¼šè¤‡æ•°ã®é¸æŠè‚¢ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
      const rootOptions = [0, 2, 4]; // I, iii, V
      const rootProbability = genreCharacteristics.rhythmComplexity > 0.7 ? 0.5 : 0.7;
      
      if (Math.random() < rootProbability) {
        return rootOptions[Math.floor(Math.random() * rootOptions.length)];
      } else {
        // ãƒ«ãƒ¼ãƒˆä»¥å¤–ã®éŸ³ç¨‹
        const nonRootOptions = [1, 3, 5, 6];
        return nonRootOptions[Math.floor(Math.random() * nonRootOptions.length)] % scaleLength;
      }
    } else {
      // ãã®ä»–ã®æ‹ï¼šã‚ˆã‚Šå¤šæ§˜ãªå‹•ã
      const direction = Math.random() < 0.5 ? -1 : 1;
      
      // è¤‡é›‘ã•ä¿‚æ•°ã‚’è€ƒæ…®ã—ãŸæœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°
      let baseVariation = genreCharacteristics.noteVariation;
      if (complexityFactor) {
        baseVariation *= complexityFactor.noteVariation;
      }
      
      // ã‚ˆã‚Šå¤§ããªã‚¸ãƒ£ãƒ³ãƒ—ã‚‚å¯èƒ½ã«ã™ã‚‹
      const maxStep = Math.ceil(baseVariation * 4); // ã‚ˆã‚Šå¤§ããªç¯„å›²
      const stepSize = Math.floor(Math.random() * maxStep) + 1;
      
      let newIndex = currentScaleIndex + (direction * stepSize);
      
      // ãƒ ãƒ¼ãƒ‰ã«ã‚ˆã‚‹éŸ³åŸŸèª¿æ•´ï¼ˆã‚ˆã‚Šå‹•çš„ï¼‰
      const energyBoost = moodCharacteristics.rhythmEnergy * 2;
      if (energyBoost > 1 && Math.random() < 0.4) { // ç¢ºç‡ã‚’ä¸Šã’ã‚‹
        newIndex += direction * 2; // ã‚ˆã‚Šå¤§ããªå‹•ã
      }
      
      // 25%ã®ç¢ºç‡ã§å®Œå…¨ã«ãƒ©ãƒ³ãƒ€ãƒ ãªéŸ³ç¬¦
      if (Math.random() < 0.25) {
        newIndex = Math.floor(Math.random() * scaleLength);
      }
      
      // ã‚¹ã‚±ãƒ¼ãƒ«ç¯„å›²å†…ã«åˆ¶é™
      return Math.max(0, Math.min(scaleLength - 1, newIndex));
    }
  }

  // ã‚¸ãƒ£ãƒ³ãƒ«ã«åŸºã¥ãä¼‘ç¬¦æŒ¿å…¥åˆ¤å®šï¼ˆæ›´æ–°ç‰ˆï¼‰
  shouldInsertRest(measurePosition, genreCharacteristics, complexityFactor = null) {
    if (measurePosition === 0) return false; // å°ç¯€ã®æœ€åˆã¯ä¼‘ç¬¦ãªã—
    
    let restProbability = genreCharacteristics.restProbability;
    if (complexityFactor) {
      restProbability *= complexityFactor.restProbability / 0.15; // æ¨™æº–å€¤ã§æ­£è¦åŒ–
    }
    
    return Math.random() < restProbability;
  }

  // è¨­å®šã®ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆï¼ˆè¨­å®šã®å¤‰æ›´ã‚’è¿½è·¡ï¼‰+ ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰
  generateSettingsHash(settings) {
    const settingsString = JSON.stringify({
      genre: settings.genre,
      mood: settings.mood,
      tempo: settings.tempo,
      duration: settings.duration,
      instruments: settings.instruments,
      complexity: settings.complexity,
      volume: settings.volume,
      timestamp: Date.now(), // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ ã—ã¦ä¸€æ„æ€§ã‚’ä¿è¨¼
      randomSeed: Math.random() // æ¯å›ç•°ãªã‚‹ã‚·ãƒ¼ãƒ‰ã‚’è¿½åŠ 
    });
    
    // ç°¡å˜ãªãƒãƒƒã‚·ãƒ¥ç”Ÿæˆ
    let hash = 0;
    for (let i = 0; i < settingsString.length; i++) {
      const char = settingsString.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // 32bitæ•´æ•°ã«å¤‰æ›
    }
    return hash.toString(16);
  }

  // ãƒ ãƒ¼ãƒ‰ã«åŸºã¥ããƒ™ãƒ­ã‚·ãƒ†ã‚£è¨ˆç®—
  calculateMoodBasedVelocity(measurePosition, moodCharacteristics) {
    let baseVelocity = moodCharacteristics.velocityBase;
    
    // å¼·æ‹ãƒ»å¼±æ‹ã®èª¿æ•´
    if (measurePosition === 0) {
      baseVelocity += 0.1; // å¼·æ‹ã‚’å¼·ã
    } else if (measurePosition === 1 || measurePosition === 3) {
      baseVelocity -= 0.1; // å¼±æ‹ã‚’å¼±ã
    }
    
    // ãƒ©ãƒ³ãƒ€ãƒ ãªå¤‰åŒ–
    const variation = (Math.random() - 0.5) * moodCharacteristics.velocityVariation;
    return Math.max(0.1, Math.min(1.0, baseVelocity + variation));
  }

  // ã‚¸ãƒ£ãƒ³ãƒ«ç‰¹æ€§ã®å–å¾—
  getGenreCharacteristics(genre) {
    const characteristics = {
      'classical': {
        rhythmComplexity: 0.7,
        restProbability: 0.15,
        noteVariation: 0.6,
        tempoVariation: 0.1,
        melodyRange: 2.0,
        chordProgression: 'traditional'
      },
      'jazz': {
        rhythmComplexity: 0.9,
        restProbability: 0.2,
        noteVariation: 0.8,
        tempoVariation: 0.15,
        melodyRange: 2.5,
        chordProgression: 'complex'
      },
      'rock': {
        rhythmComplexity: 0.6,
        restProbability: 0.1,
        noteVariation: 0.5,
        tempoVariation: 0.05,
        melodyRange: 1.5,
        chordProgression: 'power'
      },
      'electronic': {
        rhythmComplexity: 0.8,
        restProbability: 0.05,
        noteVariation: 0.9,
        tempoVariation: 0.2,
        melodyRange: 3.0,
        chordProgression: 'synthetic'
      },
      'ambient': {
        rhythmComplexity: 0.3,
        restProbability: 0.25,
        noteVariation: 0.4,
        tempoVariation: 0.05,
        melodyRange: 1.8,
        chordProgression: 'atmospheric'
      },
      'cinematic': {
        rhythmComplexity: 0.8,
        restProbability: 0.2,
        noteVariation: 0.7,
        tempoVariation: 0.3,
        melodyRange: 2.8,
        chordProgression: 'dramatic'
      }
    };
    
    return characteristics[genre] || characteristics['ambient'];
  }

  // ãƒ ãƒ¼ãƒ‰ç‰¹æ€§ã®å–å¾—
  getMoodCharacteristics(mood) {
    const characteristics = {
      'calm': {
        velocityBase: 0.5,
        velocityVariation: 0.2,
        rhythmEnergy: 0.3,
        harmonicTension: 0.2,
        tempoModifier: 0.85
      },
      'energetic': {
        velocityBase: 0.8,
        velocityVariation: 0.3,
        rhythmEnergy: 0.9,
        harmonicTension: 0.6,
        tempoModifier: 1.2
      },
      'dramatic': {
        velocityBase: 0.7,
        velocityVariation: 0.4,
        rhythmEnergy: 0.8,
        harmonicTension: 0.8,
        tempoModifier: 1.0
      },
      'peaceful': {
        velocityBase: 0.4,
        velocityVariation: 0.15,
        rhythmEnergy: 0.2,
        harmonicTension: 0.1,
        tempoModifier: 0.8
      },
      'uplifting': {
        velocityBase: 0.75,
        velocityVariation: 0.25,
        rhythmEnergy: 0.7,
        harmonicTension: 0.4,
        tempoModifier: 1.1
      },
      'melancholic': {
        velocityBase: 0.45,
        velocityVariation: 0.3,
        rhythmEnergy: 0.4,
        harmonicTension: 0.7,
        tempoModifier: 0.9
      }
    };
    
    return characteristics[mood] || characteristics['calm'];
  }

  // ã‚¸ãƒ£ãƒ³ãƒ«ã«åŸºã¥ãéŸ³ç¬¦é•·ã•ã®è¨ˆç®—
  calculateGenreBasedDuration(beatDuration, measurePosition, genreCharacteristics) {
    let baseDuration;
    
    // åŸºæœ¬çš„ãªéŸ³ç¬¦é•·ã•
    if (measurePosition === 0 || measurePosition === 2) {
      baseDuration = beatDuration; // å¼·æ‹ã¯1æ‹
    } else {
      baseDuration = beatDuration * 0.5; // å¼±æ‹ã¯åŠæ‹
    }
    
    // ã‚¸ãƒ£ãƒ³ãƒ«ã«ã‚ˆã‚‹èª¿æ•´
    const complexityFactor = 1 + (genreCharacteristics.rhythmComplexity - 0.5) * 0.5;
    return baseDuration * complexityFactor;
  }
}

// ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
window.musicGenerator = new MusicGenerator();
